Step 1...

pip install keras-tuner



Step 2...

import keras_tuner as kt




Step 3...Define the Model with Hyperparameters to Tune
You'll need to write a function that creates a Keras model while accepting hyperparameters to tune. 
Let's tune the number of units in each Dense layer, the learning rate of the optimizer, and the regularization strength.


from tensorflow import keras
from tensorflow.keras import layers, regularizers

def build_model(hp):
    model = keras.Sequential()
    model.add(layers.Dense(
        units=hp.Int('units', min_value=32, max_value=512, step=32),
        activation='relu',
        input_shape=(X_train.shape[1],),
        kernel_regularizer=regularizers.l2(hp.Float('reg_l2', min_value=1e-4, max_value=1e-2, sampling='LOG'))
    ))
    
    for i in range(hp.Int('layers', 1, 3)):  # adding 1-3 additional layers
        model.add(layers.Dense(
            units=hp.Int(f'layer_{i}_units', min_value=32, max_value=512, step=32),
            activation='relu',
            kernel_regularizer=regularizers.l2(hp.Float(f'layer_{i}_reg_l2', min_value=1e-4, max_value=1e-2, sampling='LOG'))
        ))
    
    model.add(layers.Dense(1, activation='sigmoid'))  # Output layer for binary classification
    
    # Compile the model
    hp_learning_rate = hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')
    model.compile(optimizer=keras.optimizers.Adam(learning_rate=hp_learning_rate),
                  loss='binary_crossentropy',
                  metrics=['accuracy'])
    
    return model


Step 4... Initialize and Run the Hyperparameter Search
Now you'll set up the tuner and run the hyperparameter search. Keras Tuner has several tuners available; we'll use the RandomSearch tuner for this example.


tuner = kt.RandomSearch(
    build_model,
    objective='val_accuracy',
    max_trials=10,  # The number of different configurations to try
    executions_per_trial=2,  # The number of models that should be built and fit for each trial
    directory='my_dir',  # Directory to store the tuning logs
    project_name='keras_tuner_demo'
)

# Early stopping callback
stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)

# Perform the hyperparameter tuning
tuner.search(X_train, y_train, epochs=50, validation_split=0.2, callbacks=[stop_early])

# Get the optimal hyperparameters
best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]



Step 5...Build the Model with the Optimal Hyperparameters and Retrain
Finally, you'll want to retrain your best model configuration on the full training data.



# Build the model with the best hp
model = tuner.hypermodel.build(best_hps)

# Fit the best model
history = model.fit(X_train, y_train, epochs=50, validation_split=0.2)

# Evaluate on test data
eval_result = model.evaluate(X_test, y_test)
print("[test loss, test accuracy]:", eval_result)
