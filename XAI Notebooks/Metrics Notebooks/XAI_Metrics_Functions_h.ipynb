{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00cd54c-1089-4f35-b2a9-5ddb76babfed",
   "metadata": {},
   "source": [
    "# Disseration Experiment \n",
    "# XAI Metrics - Function Implementations\n",
    "Ciaran Finnegan November 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f778e-fa58-4ac8-a3be-338a576903d0",
   "metadata": {},
   "source": [
    "## IDENTITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e83cb-a6bd-49e3-8587-92867888d03f",
   "metadata": {},
   "source": [
    "### Pseudocode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01342e6f-9bab-4d89-9450-655f3e148abc",
   "metadata": {},
   "source": [
    "- Start with first instance in test data\n",
    "- Search all other instances in test data and calculate distance from first instance (feature distance)\n",
    "- Select closest other instance to first instance, i\n",
    "- Generate explanations for all instances in test data\n",
    "- Calculate distance of first instance explanations from explanations in all other instances\n",
    "- Select closest other instance to first instance (explanation distance), t\n",
    "- Generate success if instance id (i) = instance id (t)\n",
    "- Drop first instance from test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1572efd4-a47a-4053-a888-dc2c5f34477b",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "892635a9-b223-403c-a8cc-686722a40591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67fc86a-eabc-4617-9a6c-9cd6146faa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identity_metric(features_df, xai_values_df, XAI_Type):\n",
    "    \"\"\"\n",
    "    For each instance in the feature dataframe, this function identifies the closest instance \n",
    "    based on Euclidean distance. It then does the same for the corresponding XAI Explainor values. \n",
    "    The function checks if the closest instances for both features and XAI Explainor values match.\n",
    "    \n",
    "    Returns:\n",
    "        Percentage of instances where the closest feature and XAI Explainor value instances match.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize match count to zero\n",
    "    match_count = 0\n",
    "    \n",
    "    # Loop through each instance in the feature dataframe\n",
    "    for idx, instance in features_df.iterrows():\n",
    "        # Compute the Euclidean distance between the current instance and all other instances\n",
    "        feature_distances = features_df.drop(index=idx).apply(lambda row: distance.euclidean(row, instance), axis=1)\n",
    "        \n",
    "        # Identify the index of the closest instance\n",
    "        closest_feature_idx = feature_distances.idxmin()\n",
    "        \n",
    "        # Repeat the process for XAI Explanations\n",
    "        xai_instance = xai_values_df.loc[idx]\n",
    "        xai_distances = xai_values_df.drop(index=idx).apply(lambda row: distance.euclidean(row, xai_instance), axis=1)\n",
    "        closest_xai_idx = xai_distances.idxmin()\n",
    "        \n",
    "        # Check if the closest instances for both features and XAI Explanations match\n",
    "        if closest_feature_idx == closest_xai_idx:\n",
    "            match_count += 1\n",
    "        \n",
    "        # Print the distances for debugging purposes\n",
    "        print(f\"Instance {idx}:   Current matches: {match_count}\")\n",
    "        print(f\"\\tClosest feature instance: {closest_feature_idx} (Distance: {feature_distances[closest_feature_idx]:.4f})\")\n",
    "        print(f\"\\tClosest \"+ XAI_Type + \" instance: {closest_xai_idx} (Distance: {xai_distances[closest_xai_idx]:.4f})\")\n",
    "\n",
    "    # Compute the matching percentage\n",
    "    percentage = (match_count / len(features_df)) * 100\n",
    "    print(f\"\\n\\nThis is the function in XAI_METRICS_FUNCTIONS -- IDENTITY for \" + XAI_Type + \"\\n\")\n",
    "    print(f\"\\n\\nPercentage of matches: {percentage:.2f}%   {match_count} Matches of {len(features_df)} Entries\")\n",
    "    \n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb611c6-a05f-433e-bbda-c99090e0f8d0",
   "metadata": {},
   "source": [
    "## STABILITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e491eec-d8e0-4494-8aa5-b384a30b9711",
   "metadata": {},
   "source": [
    "### Pseudocode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95511032-0f47-4381-9fe2-21fd4ad58764",
   "metadata": {},
   "source": [
    "\"Stability\" - this metric states that instances belonging to the same class must have comparable explanations\n",
    "\n",
    "- Assume that the dataset has been balanced 50:50 for fraud/non-fraud.\n",
    "- Cluster explanations of all instances in test data by k-means, include the 'predicted fraud' label.\n",
    "- Number of clusters equals label values, in this case two (fraud/non-fraud)\n",
    "- For each instance in test data\n",
    "\t- compare explanation cluster label to predicted class label\n",
    "\t- if match, then stability satisfied\n",
    "\t\n",
    "\talternatively\n",
    "\t\n",
    "\t- compare explanation cluster label in largest cluster to predicted class label\n",
    "\t- Take ratio of majority predicted class label to minority class as the stability measure (the higher the value the closer the explanation clusters map to \n",
    "\tpredicted results).\t\n",
    "\t\n",
    "Question: how do we know which explanations cluster equates to 'fraud' and which cluster equates to 'non-fraud'? If dataset is a 50:50 label split and we use \n",
    "two clusters then we can just pick one cluster (use the largest).\n",
    "\n",
    "\n",
    "The training data is balanced but the Test data is not. \n",
    "The majority class in the Test data will be non-Fraud, so assume that is \n",
    "always the largest cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9a0a25-a2f7-4219-acd5-d597a4c098ff",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696c67bd-4557-47f8-8cbe-10a3ed39dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stability_metric_y(xai_values_df, y_test, largest_label, XAI_Type):\n",
    "    \"\"\"\n",
    "    This function performs the following steps:\n",
    "    1. Clusters the XAI Explainor values into two clusters using the k-means algorithm.\n",
    "    2. Assigns the actual target value from the test dataset to each instance in the XAI Explainor values dataframe.\n",
    "    3. Calculates the percentage of rows where the target class '0' matches the cluster value '0'.\n",
    "    4. Outputs the final dataframe with cluster assignments and actual target values to a CSV file.\n",
    "    \n",
    "    Returns:\n",
    "        Percentage of instances where target class matches cluster value.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cluster the XAI Explainor values into two clusters\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42).fit(xai_values_df)\n",
    "    \n",
    "    # Get the cluster labels\n",
    "    cluster_labels = kmeans.labels_\n",
    "    \n",
    "    # Create a new dataframe with an additional column indicating the cluster assignment\n",
    "    clustered_df = xai_values_df.copy()\n",
    "    clustered_df['Cluster'] = cluster_labels\n",
    "    \n",
    "    # Display Cluser before label change\n",
    "    # print('\\nDisplay Cluster before label change')\n",
    "    # print(clustered_df)\n",
    "    \n",
    "    \n",
    "    ######################\n",
    "    \n",
    "    # Rename clusters so that the largest cluster is always labeled '0'\n",
    "    # if sum(cluster_labels) > len(cluster_labels) / 2:\n",
    "    #    clustered_df['Cluster'] = clustered_df['Cluster'].map({0: '1', 1: '0'})\n",
    "    \n",
    "    # 1. Determine the majority and minority clusters\n",
    "    cluster_counts = clustered_df['Cluster'].value_counts()\n",
    "    majority_cluster = cluster_counts.idxmax()\n",
    "    minority_cluster = 1 if majority_cluster == 0 else 0\n",
    "\n",
    "    # 2. Assign largest_label to entries in the majority cluster\n",
    "    #clustered_df['label'] = clustered_df['Cluster'].apply(lambda x: largest_label if x == majority_cluster else None)\n",
    "    clustered_df['Cluster_adj'] = clustered_df['Cluster'].apply(lambda x: str(largest_label) if x == majority_cluster else None)\n",
    "\n",
    "    # 3. Reverse the label in the minority cluster and convert to string\n",
    "    minority_label = str(1 - largest_label)\n",
    "    #clustered_df.loc[clustered_df['Cluster'] == minority_cluster, 'label'] = 1 - largest_label\n",
    "    clustered_df.loc[clustered_df['Cluster'] == minority_cluster, 'Cluster_adj'] = minority_label\n",
    "    \n",
    "    \n",
    "    ###################\n",
    "    \n",
    "    \n",
    "    # Display Cluser after label change\n",
    "    # print('\\nDisplay Cluster after label change')\n",
    "    # print(clustered_df)        \n",
    "        \n",
    "    \n",
    "    # Print the number of instances assigned to each cluster\n",
    "    # cluster_0_count = clustered_df[clustered_df['Cluster'] == '0'].shape[0]\n",
    "    # cluster_1_count = clustered_df[clustered_df['Cluster'] == '1'].shape[0]\n",
    "    \n",
    "    cluster_0_count = clustered_df[clustered_df['Cluster_adj'] == '0'].shape[0]\n",
    "    cluster_1_count = clustered_df[clustered_df['Cluster_adj'] == '1'].shape[0]\n",
    "    print(f\"Number of Instances in Cluster '0': {cluster_0_count}\")\n",
    "    print(f\"Number of Instances in Cluster '1': {cluster_1_count}\")\n",
    "    \n",
    "    # Assign the appropriate subset of y_test values to the dataframe based on the selected indices\n",
    "    clustered_df['Actual'] = y_test.loc[clustered_df.index].values\n",
    "    \n",
    "    #######################\n",
    "    \n",
    "    # Display Cluser after 'Actual' value added\n",
    "    # print('\\nDisplay Cluster after -Actual- value added... (swithced off for now')\n",
    "    #print(clustered_df)        \n",
    "    \n",
    "    #######################\n",
    "    \n",
    "    \n",
    "    # Calculate the percentage of rows where the target class '0' matches the cluster value '0'\n",
    "    # matches_0 = clustered_df[(clustered_df['Cluster'] == '0') & (clustered_df['Actual'] == 0)].shape[0]\n",
    "    # total_class_0 = clustered_df[clustered_df['Actual'] == 0].shape[0]\n",
    "    \n",
    "    # Calculate the percentage of rows where the target class '1' matches the cluster value '1'\n",
    "    # matches_1 = clustered_df[(clustered_df['Cluster'] == '1') & (clustered_df['Actual'] == 1)].shape[0]\n",
    "    # total_class_1 = clustered_df[clustered_df['Actual'] == 1].shape[0]\n",
    "    \n",
    "    \n",
    "    # Calculate the percentage of rows where the target class '0' matches the cluster value '0'\n",
    "    matches_0 = clustered_df[(clustered_df['Cluster_adj'] == '0') & (clustered_df['Actual'] == 0)].shape[0]\n",
    "    total_class_0 = clustered_df[clustered_df['Actual'] == 0].shape[0]\n",
    "    \n",
    "    # Calculate the percentage of rows where the target class '1' matches the cluster value '1'\n",
    "    matches_1 = clustered_df[(clustered_df['Cluster_adj'] == '1') & (clustered_df['Actual'] == 1)].shape[0]\n",
    "    total_class_1 = clustered_df[clustered_df['Actual'] == 1].shape[0]\n",
    "    \n",
    "    \n",
    "    # Print the results for class '0'\n",
    "    print(f\"\\nFor Class '0':\")\n",
    "    print(f\"Total Instances: total_class_0: {total_class_0}\")\n",
    "    print(f\"Matching Cluster '0' Instances (matches_0): {matches_0}\")\n",
    "    \n",
    "    # Print the results for class '1'\n",
    "    print(f\"\\nFor Class '1':\")\n",
    "    print(f\"Total Instances: total_class_1: {total_class_1}\")\n",
    "    print(f\"Matching Cluster '1' Instances (matches_1): {matches_1}\")\n",
    "    \n",
    "    # Output the final dataframe to a CSV file\n",
    "    #clustered_df.to_csv('clustered_stability.csv', index=True)\n",
    "    #print(\"\\nOutput saved to 'clustered_stability.csv'\")\n",
    "    \n",
    "    # Compute the matching percentage\n",
    "    #percentage = (matches_0 / total_class_0) * 100\n",
    "    \n",
    "    iOverallTotal = total_class_1 + total_class_0\n",
    "    total_matches = (matches_0 + matches_1)\n",
    "    percentage = ((total_matches) / iOverallTotal) * 100\n",
    "    \n",
    "    print(f\"\\n\\nThis is the function in XAI_METRICS_FUNCTIONS -- STABILITY -- \" + XAI_Type + \"\\n\")\n",
    "    print(f\"\\n\\nPercentage of matches: {percentage:.2f}% : {total_matches} Matches of {iOverallTotal} Entries\")\n",
    "    \n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cacd88-494b-414d-be1d-d90c3d6ebaae",
   "metadata": {},
   "source": [
    "## SEPERABILITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79a1ba-18a5-4220-a5a9-4d4e238a759e",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Pseudocode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f7cfc-2152-4868-86fe-2db170c69077",
   "metadata": {},
   "source": [
    "\"Seperability\" - two dissimilar instances muat have dissimilar explanations\n",
    "\n",
    "Take subset of test data and determine for each individual instance the number of duplicate\n",
    "explanations in entire subset, if any.\n",
    "\n",
    "To measure the separability metric, we choose a subset S of the testing data set that has no duplicates and get\n",
    "their explanations. Then for every instance s in S, we compare its explanation with all other explanations\n",
    "of instances in S and if such explanation has no duplicate then it satisfies the separability metric.\n",
    "\n",
    "\n",
    "\n",
    " - Choose subset S of test data\n",
    "\t\t\n",
    "\t\t-  ensure no duplicate instances exist. This is a comparison of features, \n",
    "\t\t   as no explanations have been generated yet.\n",
    "\t\t-  remove any instances with duplicated features\n",
    "\t\t-  generate explanations for each remaining instance in the subset of test data\n",
    "\t\t\n",
    " - For every instance in S\n",
    " \n",
    "\t\t- compare explanations with all other instance explanations\n",
    "\t\t- if no duplicates are found; mark instance as 'success'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9ef6f-4fea-4042-ad47-79213395ebf7",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e3bf533-73c5-4608-b101-d4dda8df1743",
   "metadata": {},
   "source": [
    "Create a function to check cell values for levels of difference across XAI results data rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5a7ef19a-08ef-4a19-a0a2-4db0837cec2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to calculate row similarity\n",
    "def is_similar_old(row1, row2, threshold=0.85):\n",
    "    similarity = (row1 == row2).mean()\n",
    "    print(f'XAI row similarity is: {similarity}')\n",
    "        \n",
    "    return similarity >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7eae145c-a295-43ca-b802-80934d8ca3c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_similar(row1, row2, threshold=0.51, tolerance=0.35):  #threshold=0.85, tolerance=0.80\n",
    "    \n",
    "    # Function to calculate similarity between two elements\n",
    "    def is_element_similar(element1, element2, tolerance):\n",
    "        if element1 == 0 and element2 == 0:\n",
    "            return True  # Avoid division by zero\n",
    "        relative_difference = abs(element1 - element2) / max(abs(element1), abs(element2))\n",
    "        #print(f'XAI relative difference (new function) is: {relative_difference}')\n",
    "        #print(f'Return value from is_element_similar(): {(relative_difference <= (1 - tolerance))}')\n",
    "        \n",
    "        return relative_difference <= (1 - tolerance)\n",
    "\n",
    "    # Calculate similarity for each element pair\n",
    "    similarities = [is_element_similar(e1, e2, tolerance) for e1, e2 in zip(row1, row2)]\n",
    "\n",
    "    # Calculate overall row similarity\n",
    "    similarity = sum(similarities) / len(similarities)\n",
    "    #print('\\n\\n###############')\n",
    "    #print(f'XAI Row similarity (new function) is: {similarity}')\n",
    "    #print(f'Return value for row from is_similar(): {(similarity >= threshold)}')\n",
    "    #print('###############\\n\\n')\n",
    "    \n",
    "    return similarity >= threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834a32e7-42f2-4326-9edb-bd87a6c39745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seperability_metric(features_df, xai_values_df, XAI_Type, threshold=0.51, tolerance=0.35):\n",
    "    # Ensure that features_df and xai_values_df have the same number of rows\n",
    "    if len(features_df) != len(xai_values_df):\n",
    "        raise ValueError(\"Seperability Metric: The two dataframes must have the same number of rows\")\n",
    "        \n",
    "    print(f'1:Before Dup check:Lenght of features df: {len(features_df)}')    \n",
    "    print(f'1:Before Dup check:Lenght of xai_values_df: {len(xai_values_df)}\\n\\n')    \n",
    "\n",
    "    # Remove duplicate rows in features_df and corresponding rows in xai_values_df\n",
    "    features_df_no_duplicates = features_df.drop_duplicates(keep='first')\n",
    "    xai_values_df = xai_values_df.loc[features_df_no_duplicates.index]\n",
    "    \n",
    "    print(f'2:After Dup check:Lenght of features df: {len(features_df)}')    \n",
    "    print(f'2:After Dup check:Lenght of xai_values_df: {len(xai_values_df)}')    \n",
    "    \n",
    "    \n",
    "\n",
    "    # Initialize counters\n",
    "    iSeperation_success = 0\n",
    "    iSeperation_failure = 0\n",
    "\n",
    "\n",
    "    # Iterate over each row in features_df\n",
    "    for index, _ in features_df_no_duplicates.iterrows():\n",
    "        # Get the corresponding row in xai_values_df\n",
    "        xai_row = xai_values_df.loc[index]\n",
    "        \n",
    "        # Debug for Feature row\n",
    "        # print(f'\\nFeature Index is: {index}')\n",
    "\n",
    "        # Check for similarity with other rows in xai_values_df\n",
    "        similarity_count = sum(is_similar(xai_row, \n",
    "                                          other_row,\n",
    "                                          threshold, \n",
    "                                          tolerance) for idx, other_row in xai_values_df.iterrows() if idx != index)\n",
    "\n",
    "        # Check if similarity_count is zero (no similar rows found)\n",
    "        if similarity_count == 0:\n",
    "            iSeperation_success += 1\n",
    "        else:\n",
    "            iSeperation_failure += 1\n",
    "            print('Failure')\n",
    "\n",
    "    # Calculate the percentage of separation success\n",
    "    separation_percentage = (iSeperation_success / len(features_df_no_duplicates)) * 100\n",
    "    \n",
    "    print(f'Result: {iSeperation_success} entries are shown to have dissimilar explanations in data block of {(len(features_df_no_duplicates))} rows')\n",
    "    \n",
    "    display_text(\"The Y Seperability Metric Score for \" + XAI_Type + \": \" + str(separation_percentage))\n",
    "\n",
    "    return separation_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25560fe-e190-4451-9cac-cec7c315f579",
   "metadata": {},
   "source": [
    "## SIMILARITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ec0ec-24a6-4ffd-a24e-99b4c299c10f",
   "metadata": {},
   "source": [
    "### Pseudocode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15de21-88fa-4150-abc0-13afe999e748",
   "metadata": {},
   "source": [
    "This metric states that the more similar the instances to be explained, the closer their explanations should be and vice versa.\n",
    "\n",
    "To measure the similarity metric, we cluster instances in the testing data set, after\n",
    "normalization using DBSCAN algorithm. For each framework, we normalize the explanations\n",
    "and calculate the mean pairwise Euclidean distances between explanations of testing instances\n",
    "in the same cluster. The framework with the smallest mean pairwise Euclidean distances across\n",
    "its clusters is the best reflecting the similarity metric.\n",
    "\n",
    " - Pass instances and their respective explanations to a function\n",
    "\n",
    " - Normalise instances in the test data(DBSCAN)\n",
    " \n",
    " - Cluster instances in test data into clusters (Note:- not just two clusters, could be more)\n",
    " \n",
    " - Group the explanations based on the cluster to which their associated instance has been assigned\n",
    " \n",
    " - Calculate mean pairwise Euclidean distance between explanations in each of the  groups (Note:- not just two groups, could be more)\n",
    " \n",
    " - Calculate the average of the two distance values just generated"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94453e15-f37a-4d19-bd0d-1299cdb4055e",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6811574f-6acf-4a66-83e6-2fdc5f32a113",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "from sklearn.metrics import davies_bouldin_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0298ce7a-7125-4dc1-b732-ec6cc46fb61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def determine_optimal_clusters_davies_bouldin(features_df: pd.DataFrame, max_clusters: int = 10) -> int:\n",
    "    \"\"\"\n",
    "    Determines the optimal number of clusters for a given DataFrame using the Davies-Bouldin Index.\n",
    "\n",
    "    Parameters:\n",
    "    features_df (pd.DataFrame): The DataFrame containing the features for clustering.\n",
    "    max_clusters (int): The maximum number of clusters to consider.\n",
    "\n",
    "    Returns:\n",
    "    int: The optimal number of clusters.\n",
    "    \"\"\"\n",
    "\n",
    "    best_db_index = float('inf')\n",
    "    best_k = 2\n",
    "\n",
    "    for k in range(2, max_clusters):\n",
    "        kmeans = KMeans(n_clusters=k, init='k-means++', random_state=42)\n",
    "        cluster_labels = kmeans.fit_predict(features_df)\n",
    "\n",
    "        db_index = davies_bouldin_score(features_df, cluster_labels)\n",
    "        if db_index < best_db_index:\n",
    "            best_db_index = db_index\n",
    "            best_k = k\n",
    "\n",
    "    return best_k\n",
    "\n",
    "# Example usage:\n",
    "# optimal_clusters = determine_optimal_clusters_davies_bouldin(features_df)\n",
    "# print(f'Optimal number of clusters: {optimal_clusters}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6230c75b-7ffe-4846-a398-bc3c8b1fadaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_metric(features_df, xai_values_df, XAI_Type, use_dbscan=True, eps=0.5, min_samples=5):\n",
    "    \n",
    "    # Ensure that features_df and xai_values_df have the same number of rows\n",
    "    if len(features_df) != len(xai_values_df):\n",
    "        raise ValueError(\"Similarity Metric: The two dataframes must have the same number of rows\")\n",
    "    \n",
    "    # Step 1: Normalize features_df using DBSCAN for outlier detection and handling\n",
    "    # Check if features_df is empty\n",
    "    if features_df.empty:\n",
    "        raise ValueError(\"Input features_df is empty.\")\n",
    "\n",
    "    # Optional DBSCAN for outlier detection\n",
    "    if use_dbscan:\n",
    "        dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "        labels = dbscan.fit_predict(features_df)\n",
    "        features_df = features_df[labels != -1]\n",
    "        xai_values_df = xai_values_df[labels != -1]\n",
    "\n",
    "        # Check if features_df is empty after DBSCAN\n",
    "        if features_df.empty:\n",
    "            raise ValueError(\"All instances were filtered out as outliers by DBSCAN.\")\n",
    "\n",
    "    # Normalizing the features \n",
    "    # This is already done as part of pre=processing feature inputs?\n",
    "    #scaler = StandardScaler()\n",
    "    #normalized_features = scaler.fit_transform(features_df)\n",
    "    \n",
    "    # Option code to look at optimising cluster values\n",
    "    optimal_clusters = determine_optimal_clusters_davies_bouldin(features_df)\n",
    "    print(f'\\nOptimal number of clusters: {optimal_clusters}')\n",
    "\n",
    "    # Step 2: Cluster normalized data using K-Means\n",
    "    # Here, we assume a fixed number of clusters or use a heuristic\n",
    "    # This can be determined using methods like the elbow method\n",
    "    #n_clusters = 3\n",
    "    n_clusters = optimal_clusters\n",
    "    kmeans = KMeans(n_clusters=n_clusters)\n",
    "    clusters = kmeans.fit_predict(features_df)\n",
    "    #clusters = kmeans.fit_predict(normalized_features)\n",
    "                         \n",
    "    # Show clusters...\n",
    "    # print(f'\\nClusters... (after kmeans fit): {clusters}')          \n",
    "                         \n",
    "\n",
    "    # Step 3: Group explanations in xai_values_df based on clusters\n",
    "    grouped_explanations = [xai_values_df[clusters == k] for k in range(n_clusters)]\n",
    "                         \n",
    "    # Show Grouped Explanations\n",
    "    # print(f'Grouped Explnations (grouped_explanations): {grouped_explanations}')      \n",
    "                         \n",
    "\n",
    "    # Step 4: Calculate mean pairwise Euclidean distance for each group\n",
    "    group_distances = [np.mean(squareform(pdist(group))) for group in grouped_explanations]\n",
    "\n",
    "    # Step 5: Calculate the overall average distance\n",
    "    average_distance = np.mean(group_distances)\n",
    "\n",
    "    \n",
    "    similarity_measure = average_distance\n",
    "    \n",
    "    display_text(\"The Similarity Metric Score for \" + XAI_Type + \": \" + str(similarity_measure))\n",
    "    \n",
    "    \n",
    "    return similarity_measure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab378be2-37d5-44bc-a225-4aceb3fc2bf6",
   "metadata": {},
   "source": [
    "## COMPUTATIONAL EFFICIENCY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d4896c-16b7-4594-8377-1cffa26bf11f",
   "metadata": {},
   "source": [
    "### Decorator Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "639e5661-fbf9-44f5-bdde-230355b3887e",
   "metadata": {},
   "source": [
    "To measure the execution time of the Python functions generating the XAI values, a decorator has been created that wraps around the XAI function. \n",
    "\n",
    "A decorator is a higher-order function in Python that allows you to extend or modify the behavior of other functions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f912177-785c-475b-a353-b4ca965619ae",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d682add3-0542-4e40-821d-0372405de2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from functools import wraps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "870b5ad2-a885-4eb3-a149-c39871ed5516",
   "metadata": {},
   "outputs": [],
   "source": [
    "def timeit(func):\n",
    "    @wraps(func)\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        execution_time = end_time - start_time\n",
    "        print(f\"Function {func.__name__!r} executed in {execution_time:.4f} seconds\")\n",
    "        return result, execution_time\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "32eef3db-b839-4d41-899d-9ec7d8ba8662",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage:\n",
    "@timeit\n",
    "def example_function():\n",
    "    # Some time-consuming task\n",
    "    time.sleep(2)  # Simulating a task taking 2 seconds\n",
    "    return \"Result\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e720bf80-4d1e-4362-9bf3-ee76e20fbb9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function 'example_function' executed in 2.0021 seconds\n",
      "Result: Result, Execution Time: 2.002138137817383 seconds\n"
     ]
    }
   ],
   "source": [
    "# When calling the function, you get both the result and the execution time\n",
    "result, exec_time = example_function()\n",
    "print(f\"Result: {result}, Execution Time: {exec_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b50c60c-1e8a-4874-a651-d2265307fd34",
   "metadata": {},
   "source": [
    "## Test Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbddbf4-e57a-454b-a687-b47df017f22b",
   "metadata": {},
   "source": [
    "### Check Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "46d6487a-1fb5-40ba-8f2c-6062419e79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_distance(instance1, instance2):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distance between two instances, considering only numerical columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - instance1 (pd.Series): The first instance.\n",
    "    - instance2 (pd.Series): The second instance.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The Euclidean distance between the two instances.\n",
    "    \"\"\"\n",
    "    # Filter out non-numerical columns\n",
    "    instance1_numeric = instance1[instance1.apply(lambda x: np.isreal(x) and not isinstance(x, bool))]\n",
    "    instance2_numeric = instance2[instance2.apply(lambda x: np.isreal(x) and not isinstance(x, bool))]\n",
    "    \n",
    "    print(\"\\nCalculating Euclidean distance...\\n\\n\")\n",
    "    \n",
    "    return np.sqrt(np.sum((instance1_numeric - instance2_numeric) ** 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
