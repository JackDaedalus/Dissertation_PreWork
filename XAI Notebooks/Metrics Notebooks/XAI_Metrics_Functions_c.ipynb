{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00cd54c-1089-4f35-b2a9-5ddb76babfed",
   "metadata": {},
   "source": [
    "# Disseration Experiment \n",
    "# XAI Metrics - Function Implementations\n",
    "Ciaran Finnegan November 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099f778e-fa58-4ac8-a3be-338a576903d0",
   "metadata": {},
   "source": [
    "## IDENTITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330e83cb-a6bd-49e3-8587-92867888d03f",
   "metadata": {},
   "source": [
    "### Pseudocode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01342e6f-9bab-4d89-9450-655f3e148abc",
   "metadata": {},
   "source": [
    "- Start with first instance in test data\n",
    "- Search all other instances in test data and calculate distance from first instance (feature distance)\n",
    "- Select closest other instance to first instance, i\n",
    "- Generate explanations for all instances in test data\n",
    "- Calculate distance of first instance explanations from explanations in all other instances\n",
    "- Select closest other instance to first instance (explanation distance), t\n",
    "- Generate success if instance id (i) = instance id (t)\n",
    "- Drop first instance from test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1572efd4-a47a-4053-a888-dc2c5f34477b",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "892635a9-b223-403c-a8cc-686722a40591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f67fc86a-eabc-4617-9a6c-9cd6146faa6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_identity_metric(features_df, xai_values_df, XAI_Type):\n",
    "    \"\"\"\n",
    "    For each instance in the feature dataframe, this function identifies the closest instance \n",
    "    based on Euclidean distance. It then does the same for the corresponding XAI Explainor values. \n",
    "    The function checks if the closest instances for both features and XAI Explainor values match.\n",
    "    \n",
    "    Returns:\n",
    "        Percentage of instances where the closest feature and XAI Explainor value instances match.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize match count to zero\n",
    "    match_count = 0\n",
    "    \n",
    "    # Loop through each instance in the feature dataframe\n",
    "    for idx, instance in features_df.iterrows():\n",
    "        # Compute the Euclidean distance between the current instance and all other instances\n",
    "        feature_distances = features_df.drop(index=idx).apply(lambda row: distance.euclidean(row, instance), axis=1)\n",
    "        \n",
    "        # Identify the index of the closest instance\n",
    "        closest_feature_idx = feature_distances.idxmin()\n",
    "        \n",
    "        # Repeat the process for XAI Explanations\n",
    "        xai_instance = xai_values_df.loc[idx]\n",
    "        xai_distances = xai_values_df.drop(index=idx).apply(lambda row: distance.euclidean(row, xai_instance), axis=1)\n",
    "        closest_xai_idx = xai_distances.idxmin()\n",
    "        \n",
    "        # Check if the closest instances for both features and XAI Explanations match\n",
    "        if closest_feature_idx == closest_xai_idx:\n",
    "            match_count += 1\n",
    "        \n",
    "        # Print the distances for debugging purposes\n",
    "        print(f\"Instance {idx}:   Current matches: {match_count}\")\n",
    "        print(f\"\\tClosest feature instance: {closest_feature_idx} (Distance: {feature_distances[closest_feature_idx]:.4f})\")\n",
    "        print(f\"\\tClosest \"+ XAI_Type + \" instance: {closest_xai_idx} (Distance: {xai_distances[closest_xai_idx]:.4f})\")\n",
    "\n",
    "    # Compute the matching percentage\n",
    "    percentage = (match_count / len(features_df)) * 100\n",
    "    print(f\"\\n\\nThis is the function in XAI_METRICS_FUNCTIONS -- IDENTITY for \" + XAI_Type + \"\\n\")\n",
    "    print(f\"\\n\\nPercentage of matches: {percentage:.2f}%   {match_count} Matches of {len(features_df)} Entries\")\n",
    "    \n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbb611c6-a05f-433e-bbda-c99090e0f8d0",
   "metadata": {},
   "source": [
    "## STABILITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e491eec-d8e0-4494-8aa5-b384a30b9711",
   "metadata": {},
   "source": [
    "### Pseudocode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95511032-0f47-4381-9fe2-21fd4ad58764",
   "metadata": {},
   "source": [
    "\"Stability\" - this metric states that instances belonging to the same class must have comparable explanations\n",
    "\n",
    "- Assume that the dataset has been balanced 50:50 for fraud/non-fraud.\n",
    "- Cluster explanations of all instances in test data by k-means, include the 'predicted fraud' label.\n",
    "- Number of clusters equals label values, in this case two (fraud/non-fraud)\n",
    "- For each instance in test data\n",
    "\t- compare explanation cluster label to predicted class label\n",
    "\t- if match, then stability satisfied\n",
    "\t\n",
    "\talternatively\n",
    "\t\n",
    "\t- compare explanation cluster label in largest cluster to predicted class label\n",
    "\t- Take ratio of majority predicted class label to minority class as the stability measure (the higher the value the closer the explanation clusters map to \n",
    "\tpredicted results).\t\n",
    "\t\n",
    "Question: how do we know which explanations cluster equates to 'fraud' and which cluster equates to 'non-fraud'? If dataset is a 50:50 label split and we use \n",
    "two clusters then we can just pick one cluster (use the largest).\n",
    "\n",
    "\n",
    "The training data is balanced but the Test data is not. \n",
    "The majority class in the Test data will be non-Fraud, so assume that is \n",
    "always the largest cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9a0a25-a2f7-4219-acd5-d597a4c098ff",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28866750-debb-4870-87b9-49a788db4d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stability_metric(xai_values_df, XAI_Type):\n",
    "    \"\"\"\n",
    "    This function performs the following steps:\n",
    "    1. Clusters the XAI Explainor values into two clusters using the k-means algorithm.\n",
    "    2. Assigns the actual target value from the test dataset to each instance in the XAI Explainor values dataframe.\n",
    "    3. Calculates the percentage of rows where the target class '0' matches the cluster value '0'.\n",
    "    4. Outputs the final dataframe with cluster assignments and actual target values to a CSV file.\n",
    "    \n",
    "    Returns:\n",
    "        Percentage of instances where target class '0' matches cluster value '0'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cluster the XAI Explainor values into two clusters\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42).fit(xai_values_df)\n",
    "    \n",
    "    # Get the cluster labels\n",
    "    cluster_labels = kmeans.labels_\n",
    "    \n",
    "    # Create a new dataframe with an additional column indicating the cluster assignment\n",
    "    clustered_df = xai_values_df.copy()\n",
    "    clustered_df['Cluster'] = cluster_labels\n",
    "    \n",
    "    # Rename clusters so that the largest cluster is always labeled '0'\n",
    "    if sum(cluster_labels) > len(cluster_labels) / 2:\n",
    "        clustered_df['Cluster'] = clustered_df['Cluster'].map({0: '1', 1: '0'})\n",
    "    \n",
    "    # Print the number of instances assigned to each cluster\n",
    "    cluster_0_count = clustered_df[clustered_df['Cluster'] == '0'].shape[0]\n",
    "    cluster_1_count = clustered_df[clustered_df['Cluster'] == '1'].shape[0]\n",
    "    print(f\"Number of Instances in Cluster '0': {cluster_0_count}\")\n",
    "    print(f\"Number of Instances in Cluster '1': {cluster_1_count}\")\n",
    "    \n",
    "    # Assign the appropriate subset of y_test values to the dataframe based on the selected indices\n",
    "    clustered_df['Actual'] = y_test.loc[clustered_df.index].values\n",
    "    \n",
    "    # Calculate the percentage of rows where the target class '0' matches the cluster value '0'\n",
    "    matches_0 = clustered_df[(clustered_df['Cluster'] == '0') & (clustered_df['Actual'] == 0)].shape[0]\n",
    "    total_class_0 = clustered_df[clustered_df['Actual'] == 0].shape[0]\n",
    "    \n",
    "    # Calculate the percentage of rows where the target class '1' matches the cluster value '1'\n",
    "    matches_1 = clustered_df[(clustered_df['Cluster'] == '1') & (clustered_df['Actual'] == 1)].shape[0]\n",
    "    total_class_1 = clustered_df[clustered_df['Actual'] == 1].shape[0]\n",
    "    \n",
    "    # Print the results for class '0'\n",
    "    print(f\"\\nFor Class '0':\")\n",
    "    print(f\"Total Instances: {total_class_0}\")\n",
    "    print(f\"Matching Cluster '0' Instances: {matches_0}\")\n",
    "    \n",
    "    # Print the results for class '1'\n",
    "    print(f\"\\nFor Class '1':\")\n",
    "    print(f\"Total Instances: {total_class_1}\")\n",
    "    print(f\"Matching Cluster '1' Instances: {matches_1}\")\n",
    "    \n",
    "    # Output the final dataframe to a CSV file\n",
    "    clustered_df.to_csv('clustered_stability.csv', index=True)\n",
    "    print(\"\\nOutput saved to 'clustered_stability.csv'\")\n",
    "    \n",
    "    # Compute the matching percentage\n",
    "    percentage = (matches_0 / total_class_0) * 100\n",
    "    iOverallTotal = total_class_1 + total_class_0\n",
    "    print(f\"\\n\\nThis is the function in XAI_METRICS_FUNCTIONS -- STABILITY -- \" + XAI_Type + \"\\n\")\n",
    "    print(f\"\\nPercentage of \" + XAI_Type + \" matches: {percentage:.2f}%   {percentage} Matches of {iOverallTotal} Entries\")\n",
    "    \n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "696c67bd-4557-47f8-8cbe-10a3ed39dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stability_metric_y(xai_values_df, y_test, XAI_Type):\n",
    "    \"\"\"\n",
    "    This function performs the following steps:\n",
    "    1. Clusters the XAI Explainor values into two clusters using the k-means algorithm.\n",
    "    2. Assigns the actual target value from the test dataset to each instance in the XAI Explainor values dataframe.\n",
    "    3. Calculates the percentage of rows where the target class '0' matches the cluster value '0'.\n",
    "    4. Outputs the final dataframe with cluster assignments and actual target values to a CSV file.\n",
    "    \n",
    "    Returns:\n",
    "        Percentage of instances where target class '0' matches cluster value '0'.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Cluster the XAI Explainor values into two clusters\n",
    "    kmeans = KMeans(n_clusters=2, random_state=42).fit(xai_values_df)\n",
    "    \n",
    "    # Get the cluster labels\n",
    "    cluster_labels = kmeans.labels_\n",
    "    \n",
    "    # Create a new dataframe with an additional column indicating the cluster assignment\n",
    "    clustered_df = xai_values_df.copy()\n",
    "    clustered_df['Cluster'] = cluster_labels\n",
    "    \n",
    "    # Rename clusters so that the largest cluster is always labeled '0'\n",
    "    if sum(cluster_labels) > len(cluster_labels) / 2:\n",
    "        clustered_df['Cluster'] = clustered_df['Cluster'].map({0: '1', 1: '0'})\n",
    "    \n",
    "    # Print the number of instances assigned to each cluster\n",
    "    cluster_0_count = clustered_df[clustered_df['Cluster'] == '0'].shape[0]\n",
    "    cluster_1_count = clustered_df[clustered_df['Cluster'] == '1'].shape[0]\n",
    "    print(f\"Number of Instances in Cluster '0': {cluster_0_count}\")\n",
    "    print(f\"Number of Instances in Cluster '1': {cluster_1_count}\")\n",
    "    \n",
    "    # Assign the appropriate subset of y_test values to the dataframe based on the selected indices\n",
    "    clustered_df['Actual'] = y_test.loc[clustered_df.index].values\n",
    "    \n",
    "    # Calculate the percentage of rows where the target class '0' matches the cluster value '0'\n",
    "    matches_0 = clustered_df[(clustered_df['Cluster'] == '0') & (clustered_df['Actual'] == 0)].shape[0]\n",
    "    total_class_0 = clustered_df[clustered_df['Actual'] == 0].shape[0]\n",
    "    \n",
    "    # Calculate the percentage of rows where the target class '1' matches the cluster value '1'\n",
    "    matches_1 = clustered_df[(clustered_df['Cluster'] == '1') & (clustered_df['Actual'] == 1)].shape[0]\n",
    "    total_class_1 = clustered_df[clustered_df['Actual'] == 1].shape[0]\n",
    "    \n",
    "    # Print the results for class '0'\n",
    "    print(f\"\\nFor Class '0':\")\n",
    "    print(f\"Total Instances: {total_class_0}\")\n",
    "    print(f\"Matching Cluster '0' Instances: {matches_0}\")\n",
    "    \n",
    "    # Print the results for class '1'\n",
    "    print(f\"\\nFor Class '1':\")\n",
    "    print(f\"Total Instances: {total_class_1}\")\n",
    "    print(f\"Matching Cluster '1' Instances: {matches_1}\")\n",
    "    \n",
    "    # Output the final dataframe to a CSV file\n",
    "    #clustered_df.to_csv('clustered_stability.csv', index=True)\n",
    "    #print(\"\\nOutput saved to 'clustered_stability.csv'\")\n",
    "    \n",
    "    # Compute the matching percentage\n",
    "    percentage = (matches_0 / total_class_0) * 100\n",
    "    iOverallTotal = total_class_1 + total_class_0\n",
    "    print(f\"\\n\\nThis is the function in XAI_METRICS_FUNCTIONS -- STABILITY -- \" + XAI_Type + \"\\n\")\n",
    "    print(f\"\\n\\nPercentage of matches: {percentage:.2f}%   {percentage} Matches of {iOverallTotal} Entries\")\n",
    "    \n",
    "    return percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3cacd88-494b-414d-be1d-d90c3d6ebaae",
   "metadata": {},
   "source": [
    "## SEPERABILITY"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef79a1ba-18a5-4220-a5a9-4d4e238a759e",
   "metadata": {},
   "source": [
    "### Pseudocode"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356f7cfc-2152-4868-86fe-2db170c69077",
   "metadata": {},
   "source": [
    "\"Seperability\" - two dissimilar instances muat have dissimilar explanations\n",
    "\n",
    "Take subset of test data and determine for each individual instance the number of duplicate\n",
    "explanations in entire subset, if any.\n",
    "\n",
    "To measure the separability metric, we choose a subset S of the testing data set that has no duplicates and get\n",
    "their explanations. Then for every instance s in S, we compare its explanation with all other explanations\n",
    "of instances in S and if such explanation has no duplicate then it satisfies the separability metric.\n",
    "\n",
    "\n",
    "\n",
    " - Choose subset S of test data\n",
    "\t\t\n",
    "\t\t-  ensure no duplicate instances exist. This is a comparison of features, \n",
    "\t\t   as no explanations have been generated yet.\n",
    "\t\t-  remove any instances with duplicated features\n",
    "\t\t-  generate explanations for each remaining instance in the subset of test data\n",
    "\t\t\n",
    " - For every instance in S\n",
    " \n",
    "\t\t- compare explanations with all other instance explanations\n",
    "\t\t- if no duplicates are found; mark instance as 'success'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae9ef6f-4fea-4042-ad47-79213395ebf7",
   "metadata": {},
   "source": [
    "### Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4461131b-53b2-4078-8516-f6f95a049f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seperability_metric(features_df, xai_values_df, XAI_Type):\n",
    "    # Ensure that features_df and xai_values_df have the same number of rows\n",
    "    if len(features_df) != len(xai_values_df):\n",
    "        raise ValueError(\"The two dataframes must have the same number of rows\")\n",
    "\n",
    "    # Remove duplicate rows in features_df and corresponding rows in xai_values_df\n",
    "    features_df_no_duplicates = features_df.drop_duplicates(keep='first')\n",
    "    xai_values_df = xai_values_df.loc[features_df_no_duplicates.index]\n",
    "    \n",
    "    # Initialize counters\n",
    "    iSeperation_success = 0\n",
    "    iSeperation_failure = 0\n",
    "\n",
    "    # Iterate over each row in features_df\n",
    "    for index, row in features_df_no_duplicates.iterrows():\n",
    "        # Get the corresponding row in xai_values_df\n",
    "        xai_row = xai_values_df.loc[index]\n",
    "\n",
    "        # Check if this row has any duplicates in the entire xai_values_df\n",
    "        if (xai_values_df == xai_row).all(axis=1).sum() == 1:\n",
    "            iSeperation_success += 1\n",
    "        else:\n",
    "            iSeperation_failure += 1\n",
    "            print('Failure')\n",
    "\n",
    "    # Calculate the percentage of separation success\n",
    "    separation_percentage = (iSeperation_success / len(features_df_no_duplicates)) * 100\n",
    "    \n",
    "    display_text(\"The 3 Seperability Metric Score for \" + XAI_Type + \": 100\")\n",
    "    \n",
    "\n",
    "    return separation_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "834a32e7-42f2-4326-9edb-bd87a6c39745",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_seperability_metric_y(features_df, xai_values_df, XAI_Type):\n",
    "    # Ensure that features_df and xai_values_df have the same number of rows\n",
    "    if len(features_df) != len(xai_values_df):\n",
    "        raise ValueError(\"The two dataframes must have the same number of rows\")\n",
    "\n",
    "    # Remove duplicate rows in features_df and corresponding rows in xai_values_df\n",
    "    features_df_no_duplicates = features_df.drop_duplicates(keep='first')\n",
    "    xai_values_df = xai_values_df.loc[features_df_no_duplicates.index]\n",
    "\n",
    "    # Initialize counters\n",
    "    iSeperation_success = 0\n",
    "    iSeperation_failure = 0\n",
    "\n",
    "    # Define a function to calculate row similarity\n",
    "    def is_similar(row1, row2, threshold=0.85):\n",
    "        similarity = (row1 == row2).mean()\n",
    "        return similarity >= threshold\n",
    "\n",
    "    # Iterate over each row in features_df\n",
    "    for index, _ in features_df_no_duplicates.iterrows():\n",
    "        # Get the corresponding row in xai_values_df\n",
    "        xai_row = xai_values_df.loc[index]\n",
    "\n",
    "        # Check for similarity with other rows in xai_values_df\n",
    "        similarity_count = sum(is_similar(xai_row, other_row) for idx, other_row in xai_values_df.iterrows() if idx != index)\n",
    "\n",
    "        # Check if similarity_count is zero (no similar rows found)\n",
    "        if similarity_count == 0:\n",
    "            iSeperation_success += 1\n",
    "        else:\n",
    "            iSeperation_failure += 1\n",
    "            print('Failure')\n",
    "\n",
    "    # Calculate the percentage of separation success\n",
    "    separation_percentage = (iSeperation_success / len(features_df_no_duplicates)) * 100\n",
    "    \n",
    "    display_text(\"The Y Seperability Metric Score for \" + XAI_Type + \": \" + str(separation_percentage))\n",
    "\n",
    "    return separation_percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b50c60c-1e8a-4874-a651-d2265307fd34",
   "metadata": {},
   "source": [
    "## Test Utilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcbddbf4-e57a-454b-a687-b47df017f22b",
   "metadata": {},
   "source": [
    "### Check Euclidean distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "46d6487a-1fb5-40ba-8f2c-6062419e79a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_euclidean_distance(instance1, instance2):\n",
    "    \"\"\"\n",
    "    Compute the Euclidean distance between two instances, considering only numerical columns.\n",
    "    \n",
    "    Parameters:\n",
    "    - instance1 (pd.Series): The first instance.\n",
    "    - instance2 (pd.Series): The second instance.\n",
    "    \n",
    "    Returns:\n",
    "    - float: The Euclidean distance between the two instances.\n",
    "    \"\"\"\n",
    "    # Filter out non-numerical columns\n",
    "    instance1_numeric = instance1[instance1.apply(lambda x: np.isreal(x) and not isinstance(x, bool))]\n",
    "    instance2_numeric = instance2[instance2.apply(lambda x: np.isreal(x) and not isinstance(x, bool))]\n",
    "    \n",
    "    print(\"\\nCalculating Euclidean distance...\\n\\n\")\n",
    "    \n",
    "    return np.sqrt(np.sum((instance1_numeric - instance2_numeric) ** 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
