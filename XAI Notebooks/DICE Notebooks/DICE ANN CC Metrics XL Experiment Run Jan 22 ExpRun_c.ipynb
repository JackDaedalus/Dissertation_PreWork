{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6a486b-7a72-4691-8f57-260d79c5b234",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Disseration Experiment 6k\n",
    "# Generate DICE Output (Credit Card Fraud) - Experiment Jan 22¶\n",
    "Ciaran Finnegan January 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf1fe4-b634-4d96-9d71-ca3c511196b2",
   "metadata": {},
   "source": [
    "# Import Libraries + Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3199cb23-d506-4576-8658-9c9e3ea1db33",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8884cf21-2d0d-457b-b738-8a9280059051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Display libraries\n",
    "from IPython.display import display, HTML\n",
    "from prettytable import PrettyTable\n",
    "import raiutils\n",
    "from raiutils.exceptions import UserConfigValidationException\n",
    "\n",
    "\n",
    "# Import necessary libraries for DICE explainer\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers  # helper functions\n",
    "\n",
    "\n",
    "# Import necessary libraries for NN Modelling\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# Libraries required for metrics calculations\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# Libraries for Supplementary Model Evaluation\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Classifier training (not used for explainability)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Libraries used in Experiment Creation of XL Output Metrics\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b9bdf-7e9b-4392-ab7a-201fa73a72d3",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026204c6-487b-493b-ba0e-d183313deb9b",
   "metadata": {},
   "source": [
    "Dataset Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe990ca-e2ae-4ff2-8717-6b44611d9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./DS_Visualisation_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5be5fc-a8db-4305-b5f8-922019057b68",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b526b8-52c3-442b-9c13-9318d7601e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./XAI_Metrics_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5c28d-0c07-4f7e-ab3a-3234ef4bd08c",
   "metadata": {},
   "source": [
    "Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec1dbd5-037d-47ec-9c04-2b27599a3048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./DS_Model_Build_Evaluation_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812d5845-3804-409e-89e6-6407aed98ef8",
   "metadata": {},
   "source": [
    "Track Experiment Result Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5de81e-14ce-47f6-9dde-d6a90cfb0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./XAI_Experiment_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e54ff1-79b6-4f97-9052-bcd154126e1c",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72daa4d5-8380-4e9d-b7f0-8c4fabd0deb6",
   "metadata": {},
   "source": [
    "A Neural Network Model has been created in another Kubeflow Notebook and is being used in all the XAI experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb8365-904e-44f9-b985-d702de36d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('ccfraud_model')  # If saved as SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b737778-ebbe-46ac-9fd8-9616323b6b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_loaded, y_test_loaded, X_train_loaded, y_train_loaded, df_downsampled_loaded, dfCatCols = load_CC_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9200d15-6454-45ff-a613-13bfd0d9ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_loaded.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1947f79-7359-4e69-ad5e-e5db6f9059c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_loaded.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7515a5-f146-4af2-abb4-94c621418ad5",
   "metadata": {},
   "source": [
    "## Re-Display Model Peformance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb898c44-e5c5-499c-8045-1f09edc4441c",
   "metadata": {},
   "source": [
    "For illustration, the evualtion metrics of the NN model will be repeated here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81b105-1170-4978-ad30-7c6b6d35fe0e",
   "metadata": {},
   "source": [
    "### Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd2944-6747-4263-8bd7-bff2033d12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scale_loaded = StandardScaler()   \n",
    "scale_loaded_wf = StandardScaler()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a128b83-7995-4362-a443-65a83b065a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data\n",
    "X_train_loaded_scaled = scale_loaded.fit_transform(X_train_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d056a3-a743-494f-8360-a9b80616f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data\n",
    "X_test_loaded_scaled  = scale_loaded.transform(X_test_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7316252-28e5-45cb-af67-346f27086a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the 'Fraud' column and store it in a new dataframe\n",
    "df_fraudlabel = df_downsampled_loaded[['Fraud']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320330a-e8c2-4dbb-8e5f-2684e7803c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraudlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a444b1ae-93de-40b2-b085-22c5d2f40c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'Fraud' column from the original dataframe\n",
    "#df_downsampled_loaded = df_downsampled_loaded.drop(columns=['Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8640f6-a280-4aa4-87f4-f017473c71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transform() function on the remaining dataframe\n",
    "#df_downsampled_loaded_scaled = scale_loaded.transform(df_downsampled_loaded)\n",
    "df_downsampled_loaded_scaled = scale_loaded_wf.fit_transform(df_downsampled_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406f7b6-ce52-42af-b6b3-1bc6bceb4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the scaled array back to a DataFrame\n",
    "df_downsampled_loaded_scaled = pd.DataFrame(df_downsampled_loaded_scaled, \n",
    "                                            columns=df_downsampled_loaded.columns,\n",
    "                                            index=df_downsampled_loaded.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ab11e-d4ca-41f1-82ac-a443eeac33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the scaled dataframe with the 'Fraud' column\n",
    "#df_downsampled_loaded_scaled = pd.concat([df_downsampled_loaded_scaled, df_fraudlabel], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae415b7-0f04-43f0-acd9-447d47e8af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled_loaded_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe30fbb-7c68-4cdd-8b76-ef69ecdd5881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled_loaded_scaled['Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac63791-c7e9-4ea4-be40-d94e52498495",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_loaded = display_model_metrics_tabular(loaded_model, X_test_loaded_scaled, y_test_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3423934-e8fa-4142-a988-cd3ff29875f8",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111fcdb-8143-4cc9-9f70-16459e90880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_confusion_matrix(y_test_loaded, y_pred_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8072535-5a1e-4a6b-be40-58e0e85cf8d9",
   "metadata": {},
   "source": [
    "# Generate DiCE Values (Examples Instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f678e7-85d0-4884-aa8c-520c45f55a45",
   "metadata": {},
   "source": [
    "## Generate the Counterfactuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dfe2d9-adf3-40e1-ab50-38723985bf54",
   "metadata": {},
   "source": [
    "### Use Tensor Flow - Prepare DiCE parameters - CC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2dd0d-f937-458f-b043-d79f99c0d7bb",
   "metadata": {},
   "source": [
    "#### Read External File Containing list of Continous Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806068de-f7cf-4f69-b1c7-cce897f84034",
   "metadata": {},
   "source": [
    "An analysis, external to this Notebook, has taken place to identify the set of continous features that will be use din this experiment to generate Counterfactual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b97a86-998a-41eb-8b74-439bbc4b2c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file with list of continuous features for which to generate the DiCE Counterfactuals\n",
    "def read_cc_features(file_path):\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter the data where Rank is 39 or between 41 and 53 (inclusive)\n",
    "    filtered_data = data[(data['RANK'] == 39) | ((data['RANK'] >= 41) & (data['RANK'] <= 55))]\n",
    "\n",
    "    # Extract the 'Feature' column values and return them as a list\n",
    "    feature_list = filtered_data['FEATURE'].tolist()\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725100a8-dfc1-4ffa-9f67-02c06d49d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the file is in the same directory as Notebook\n",
    "file_path = 'Select_CC_Fraud_Features_v1_1.csv'\n",
    "cc_continuous_features_list = read_cc_features(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f345bda-b12b-4b8d-92de-f0be85ff9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display List of continous features loaded from external XL file.\n",
    "#cc_continuous_features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b6253a-8ae0-419c-9e1a-af9e7580358b",
   "metadata": {},
   "source": [
    "#### Verify DiCE Counterfactual Data Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99111b08-aeb2-426c-87cf-a66f07002a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of columns from loaded dataframe\n",
    "#original_cols_names = df_downsampled_loaded.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d17d86-e27e-48f5-bcbb-5dab5006d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "#df_downsampled_loaded_scaled = pd.DataFrame(df_downsampled_loaded_scaled, columns=original_cols_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131c5d4-82e2-47c7-bc43-13f7fb7e3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled_loaded_scaled['Fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e98b8e-6754-459b-b08e-ad1be9d26c12",
   "metadata": {},
   "source": [
    "#### Build DiCE Counterfactual Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a29c0-cda4-42bb-8504-ba81f13a17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "# Define the data for DiCE based on your DataFrame\n",
    "d = dice_ml.Data(dataframe=df_downsampled_loaded_scaled, \n",
    "                 continuous_features=cc_continuous_features_list, \n",
    "                 outcome_name='Fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3246ef5-99c1-4aec-8e5e-ac658541bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the backend as TensorFlow and link the model\n",
    "m = dice_ml.Model(model=loaded_model, backend='TF2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24ee56-d3fe-44f5-85e6-f9d51010fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DiCE\n",
    "exp = dice_ml.Dice(d, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d78a16-7aa8-42f9-8405-ecd27f2e1b04",
   "metadata": {},
   "source": [
    "#### Example 1: Sample DiCE Counterfactual example (x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f2fd9a-3f65-4fd2-b6e4-869944fb945c",
   "metadata": {},
   "source": [
    "The code below provides examples of generated counterfactuals. In the first two examples, for each instance entry the code has generated five counterfactuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a496200-75b8-4e7a-9d27-bd849acba23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'X_test' is a numpy array and you have a list of the original column names\n",
    "#feature_names = [col for col in df_downsampled_loaded.columns if col != 'Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc859e-8542-4ca7-8392-5ce5ae6c515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "#X_test_loaded_scaled = pd.DataFrame(X_test_loaded_scaled, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e65961-7fc4-45ba-8b4b-691b08805324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "#query_instances = X_test_loaded_scaled.iloc[0:2]#.drop('Fraud', axis=1)  # Taking the first two instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb22a3-dbc9-47e1-ae98-9c11f6537a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change query instances to match the instances you are interested in\n",
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "query_instances = df_downsampled_loaded_scaled.iloc[0:2].drop('Fraud', axis=1)  # Taking the first two instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f230c6-2d7b-4e42-a4f1-8bb29a2cb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactual explanations\n",
    "counterfactuals = exp.generate_counterfactuals(query_instances, total_CFs=5, desired_class=\"opposite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fcfaa9-fd18-4168-9743-38a54affacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the counterfactual explanations\n",
    "counterfactuals.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4097bdc-9336-4dae-bb31-1ab5c394aede",
   "metadata": {},
   "source": [
    "Reverse Scale the ouptut to make the visualisation more meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97be4a4-ee2f-4b41-aa84-f486e7ce61bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Retrieve counterfactuals as a DataFrame\n",
    "cf_df = counterfactuals.cf_examples_list[0].final_cfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe82ee-128f-439f-88e8-a360974d7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Inverse scale the counterfactuals\n",
    "#cf_df_inverse_scaled = pd.DataFrame(scaler.inverse_transform(cf_df), columns=cf_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1eaf7a-3093-4c20-be5f-5e818889e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Inverse scale the counterfactuals\n",
    "cf_df_inverse_scaled = pd.DataFrame(scale_loaded_wf.inverse_transform(cf_df), columns=cf_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44071e3e-da91-41fb-a124-42c0d191a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Visualize the inverse scaled counterfactuals\n",
    "# You can now use cf_df_inverse_scaled for a more interpretable visualization\n",
    "# For example, you can print it or use any visualization library like matplotlib, seaborn, etc.\n",
    "#print(cf_df_inverse_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c121124-da30-405f-907b-14e3fdab3eff",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf6863-ec2e-49ab-b1a0-bca59217d9fd",
   "metadata": {},
   "source": [
    "#### Example 2: Counterfactual - Highlighted Display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478d0ba-8151-4680-9f0a-2f67d56aead6",
   "metadata": {},
   "source": [
    "This example uses a display routine to improve the visual highlighting of the counterfactuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6119a25-7da1-48ad-b840-58f60b667dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactuals\n",
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "query_instance = df_downsampled_loaded_scaled.iloc[0:1].drop('Fraud', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc9f47-1942-4a23-91df-75abc3fcbb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactuals\n",
    "dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=5, desired_class=\"opposite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7d270-4730-47e4-b426-c6543567eef9",
   "metadata": {},
   "source": [
    "#### Visualize Counterfactuals (Single Set) - No Highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7acf9c-018e-4244-b901-11e1c7eaa3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_exp.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f0511-2a3e-47a8-95cf-3087d84875c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_visualize_counterfactuals(query_instance, scaler, exp, total_CFs=5, desired_class=\"opposite\"):\n",
    "    # Generate counterfactuals\n",
    "    dice_expv = exp.generate_counterfactuals(query_instance, total_CFs=total_CFs, desired_class=desired_class)\n",
    "    \n",
    "    # Extract counterfactuals as a DataFrame\n",
    "    cf_dfv = dice_expv.cf_examples_list[0].final_cfs_df\n",
    "    \n",
    "    # Inverse scale the counterfactuals\n",
    "    cf_df_inverse_scaled = pd.DataFrame(scaler.inverse_transform(cf_dfv), columns=cf_dfv.columns)\n",
    "    \n",
    "    # Visualize the inverse scaled counterfactuals\n",
    "    return cf_df_inverse_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89bd1ad-15b5-44b0-8ed5-72171427956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "query_instance = df_downsampled_loaded_scaled.iloc[0:1].drop('Fraud', axis=1)\n",
    "#inverse_scaled_cfs = generate_and_visualize_counterfactuals(query_instance, scale_loaded, exp)\n",
    "#print(inverse_scaled_cfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b70a10-3a75-4c66-b5c6-15195fd8945b",
   "metadata": {},
   "source": [
    "#### Visualize Counterfactuals (Single Set) - With Highlights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448bc39-fcc0-4ccb-9583-3d91cd3223fc",
   "metadata": {},
   "source": [
    "##### Create Display Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007cfb4-047c-4ff2-9cbc-92e368937822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_differences(query_instance, counterfactuals_df):\n",
    "    \"\"\"\n",
    "    Compares a query instance (as a Series) with counterfactual instances in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - query_instance (pd.Series): The original data instance.\n",
    "    - counterfactuals_df (pd.DataFrame): DataFrame containing counterfactual instances.\n",
    "    \n",
    "    Returns:\n",
    "    - A styled DataFrame where:\n",
    "        * The original instance is highlighted entirely.\n",
    "        * Cells with differences in counterfactuals are highlighted.\n",
    "    \"\"\"\n",
    "    # Convert query_instance to DataFrame and concatenate with counterfactuals_df\n",
    "    combined_df = pd.concat([query_instance.to_frame().T, counterfactuals_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    def highlight_cells(row):\n",
    "        \"\"\"Helper function to apply the styling.\"\"\"\n",
    "        if row.name == 0:  # If it's the original instance\n",
    "            return ['background-color: lightblue' for _ in row.index]\n",
    "        \n",
    "        # For counterfactual rows\n",
    "        colors = []\n",
    "        for col in row.index:\n",
    "            original_value = query_instance[col]\n",
    "            cf_value = row[col]\n",
    "            \n",
    "            # Convert to the same data type if they are different\n",
    "            if type(original_value) != type(cf_value):\n",
    "                try:\n",
    "                    original_value = type(cf_value)(original_value)\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        cf_value = type(original_value)(cf_value)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "            \n",
    "            # Handle float comparisons with a small tolerance\n",
    "            if isinstance(original_value, float) and isinstance(cf_value, float):\n",
    "                if abs(original_value - cf_value) < 1e-9:\n",
    "                    colors.append('')\n",
    "                else:\n",
    "                    colors.append('background-color: yellow')\n",
    "            elif original_value != cf_value:\n",
    "                colors.append('background-color: yellow')\n",
    "            else:\n",
    "                colors.append('')\n",
    "        return colors\n",
    "    \n",
    "    styled_df = combined_df.style.apply(highlight_cells, axis=1)\n",
    "    return styled_df\n",
    "\n",
    "# This refined version of the function should handle potential data type mismatches better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6aa2a2-def6-4f69-9074-d7d30fd3bb90",
   "metadata": {},
   "source": [
    "##### Display Differences - with Highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e04381-77c1-40e0-bbbd-38c084487e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Extract counterfactuals to a DataFrame\n",
    "your_actual_counterfactuals_df = dice_exp.cf_examples_list[0].final_cfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414fec3-1d5e-4ab7-a7df-03474a3030ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse scale the counterfactuals\n",
    "actual_counterfactuals_df_inverse_scaled = pd.DataFrame(scale_loaded_wf.inverse_transform(your_actual_counterfactuals_df), \n",
    "                                                        columns=your_actual_counterfactuals_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c1410-a4cd-44a2-965b-0f18998e85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your_actual_counterfactuals_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9e621-15f2-453d-966a-e57549619abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instance_series = df_downsampled_loaded.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c1e60-f834-4040-84ba-c8315741437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#styled_result = highlight_differences(query_instance_series, your_actual_counterfactuals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413696a-5ad0-4d43-8d2d-a4bb9149b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_result = highlight_differences(query_instance_series, actual_counterfactuals_df_inverse_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc8ea0-7328-4ca1-9532-09d00f0d9f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualize differences\n",
    "display(styled_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb90b7-d202-4c0e-9091-e9bb718189e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_downsampled_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34348f69-df3d-4241-8ad2-550387e2339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_differences_modified(query_instance, counterfactuals_df):\n",
    "    # Adjust 'Fraud' value in counterfactuals_df\n",
    "    fraud_value = 1 if query_instance['Fraud'] == 0 else 0\n",
    "    counterfactuals_df['Fraud'] = fraud_value\n",
    "\n",
    "    # Convert query_instance to DataFrame and concatenate with counterfactuals_df\n",
    "    combined_df = pd.concat([query_instance.to_frame().T, counterfactuals_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "    def highlight_cells(row):\n",
    "        \n",
    "        \"\"\"Helper function to apply the styling.\"\"\"\n",
    "        if row.name == 0:  # If it's the original instance\n",
    "            return ['background-color: lightblue' for _ in row.index]\n",
    "        \n",
    "        # Styling function\n",
    "        colors = []\n",
    "        for col in row.index:\n",
    "            original_value = query_instance[col]\n",
    "            cf_value = row[col]\n",
    "\n",
    "            # Convert to the same data type if they are different\n",
    "            if type(original_value) != type(cf_value):\n",
    "                try:\n",
    "                    original_value = type(cf_value)(original_value)\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        cf_value = type(original_value)(cf_value)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "            # Handle float comparisons with increased tolerance\n",
    "            if isinstance(original_value, float) and isinstance(cf_value, float):\n",
    "                if abs(original_value - cf_value) <= 1.00:\n",
    "                    colors.append('')\n",
    "                else:\n",
    "                    colors.append('background-color: yellow')\n",
    "            elif original_value != cf_value:\n",
    "                colors.append('background-color: yellow')\n",
    "            else:\n",
    "                colors.append('')\n",
    "        return colors\n",
    "\n",
    "    styled_df = combined_df.style.apply(highlight_cells, axis=1).format(\"{:.2f}\", na_rep=\"-\")\n",
    "    return styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4939551-2aad-4577-b3d4-68a305e59201",
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_result = highlight_differences_modified(query_instance_series, actual_counterfactuals_df_inverse_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abbf2a-e4d0-4b86-812b-4719a2b17e41",
   "metadata": {},
   "source": [
    "Display DiCE Counterfactuals for Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576cb07b-ec76-46d8-b64a-8af80d063b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualize differences\n",
    "display(styled_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b94da-d0a4-4bf0-9d6d-f43a20d4df56",
   "metadata": {},
   "source": [
    "# Prepare DiCE Input for Metric Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5733b8-aad3-4ae2-a491-4f3322d37801",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def generate_counterfactuals_for_instances(df, exp_block, num_instances=20, sLabel='Fraud'):\n",
    "    \"\"\"\n",
    "    Generate counterfactual explanations for a specified number of instances from a dataframe.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataframe containing the original instances.\n",
    "    - num_instances (int): The number of instances for which to generate counterfactuals.\n",
    "    \n",
    "    Returns:\n",
    "    - original_instances_df (pd.DataFrame): DataFrame containing the original instances.\n",
    "    - counterfactuals_df (pd.DataFrame): DataFrame containing the counterfactual explanations.\n",
    "    \"\"\"\n",
    "    # Prepare an empty dataframe for counterfactuals\n",
    "    counterfactuals_list = []\n",
    "    \n",
    "    #######################\n",
    "    \n",
    "    # Select a subset of the data for explanation (first nn instances)\n",
    "    if num_instances > 0:\n",
    "        \n",
    "        #instances_to_explain = data_features.iloc[:limit, :]#25\n",
    "        # Select the first 'num_instances' from the dataframe\n",
    "        original_instances_df = df.head(num_instances)\n",
    "    \n",
    "    else:\n",
    "        # Select all input feature for which to generate SHAP values\n",
    "        original_instances_df = df\n",
    "        \n",
    "    #######################\n",
    "    \n",
    "    # Select the first 'num_instances' from the dataframe\n",
    "    #original_instances_df = df.head(num_instances)\n",
    "    \n",
    "    for index, instance in original_instances_df.iterrows():\n",
    "    #for _, instance in original_instances_df.iterrows():\n",
    "        # Convert the instance to DataFrame\n",
    "        \n",
    "        print(f\"Processing row number: {index}\")\n",
    "        #print(instance['OnlinePOSCount.cnt.day.present'])\n",
    "        \n",
    "        instance_df = instance.drop(sLabel).to_frame().T\n",
    "        #instance_df = instance.drop('default').to_frame().T\n",
    "        #instance_df = instance.to_frame().T\n",
    "        \n",
    "        print(f'instance_df[OnlinePOSCount.cnt.day.present]: {instance_df[\"OnlinePOSCount.cnt.day.present\"]}')\n",
    "\n",
    "        # Generate counterfactual for the instance\n",
    "        # dice_exp = exp.generate_counterfactuals(instance_df, total_CFs=1, desired_class=\"opposite\")\n",
    "        #exp_block\n",
    "        dice_exp_block = exp_block.generate_counterfactuals(instance_df, total_CFs=1, desired_class=\"opposite\")\n",
    "        \n",
    "        \n",
    "        # Extract the counterfactual to a DataFrame\n",
    "        cf_df = dice_exp_block.cf_examples_list[0].final_cfs_df.drop(sLabel, axis=1)\n",
    "        #cf_df = dice_exp.cf_examples_list[0].final_cfs_df.drop('default', axis=1)\n",
    "        #cf_df = dice_exp.cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        # Append the counterfactual to the list\n",
    "        counterfactuals_list.append(cf_df.iloc[0])\n",
    "    \n",
    "    # Reset Indexes of Output for alignment into XAI Metrics functions\n",
    "    original_instances_df = original_instances_df.reset_index(drop=True)\n",
    "    counterfactuals_df = pd.DataFrame(counterfactuals_list).reset_index(drop=True)\n",
    "    \n",
    "    return original_instances_df, counterfactuals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ce31c-f80b-4d5f-a666-48e31fc11d65",
   "metadata": {},
   "source": [
    "# XAI Experiments - Metrics Capture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e223116-befa-4ea5-a1ef-082a8cb2b53d",
   "metadata": {},
   "source": [
    "## Suppress Warnings to clean up output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f98fd8-7e35-439d-aec6-60a5bb7c32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf93e6-78ed-4595-855a-6f187d2d226f",
   "metadata": {},
   "source": [
    "## Break out Model Test Data into a list of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb03a92-2859-4b38-b8cc-909280d10c3d",
   "metadata": {},
   "source": [
    "### Create Test Data for Experiment Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594c5d4-5cf1-4726-9a5f-ca605de1ef9f",
   "metadata": {},
   "source": [
    "Step 1: Ensure 'X_test' and 'y_test' Are DataFrames with Proper Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093213b5-d0f5-4627-b12d-accf13fc894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'X_test' is a numpy array and you have a list of the original column names\n",
    "original_feature_names = [col for col in df_downsampled_loaded.columns if col != 'Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a2fe5-e796-4494-9d5f-9b2396c60fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure X_test_loaded has the correct column names (if necessary)\n",
    "#X_test_loaded.columns = original_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db3134-edb5-4bcd-8ea7-a5a9fc7891aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "# Convert NumPy array to DataFrame\n",
    "X_test_loaded_scaled = pd.DataFrame(X_test_loaded_scaled, columns=original_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90caafcb-7f63-4052-9708-2e03dee27b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine X_test_loaded and y_test into a single DataFrame\n",
    "df_TestData = pd.concat([X_test_loaded_scaled, y_test_loaded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f88cb-f47c-40c1-910d-78699a001cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TestData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a884210-9f03-42e8-9f9e-ffc6d7bda9b3",
   "metadata": {},
   "source": [
    "### Split the DataFrame into 20 consecutive smaller DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4c912-6b45-49be-a9c0-f69ef18a329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into 20 consecutive smaller DataFrames\n",
    "split_size, list_df = split_TestData_into_nn_Blocks(df_TestData, num_splits = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc4097-c44e-40a3-869d-852bea9509f4",
   "metadata": {},
   "source": [
    "### Check Label Count for Stability Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a06e73-02a2-46f2-aa74-445c51fa82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrence of each unique value in the 'Fraud' column\n",
    "fraud_counts = df_TestData['Fraud'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Breakdown of 'Fraud' and non-Fraud label records in df_TestData:\")\n",
    "print(fraud_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd669b36-5b95-4a5a-bd6c-75c5f50d370e",
   "metadata": {},
   "source": [
    "### Add a routine to check output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06a179-82ce-4975-9879-02e1a762cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display starting points in the first nn sub dataframes\n",
    "startBlockDisplay(df_TestData, split_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab48bd-aa44-458c-892e-aeb8be308876",
   "metadata": {},
   "source": [
    "## Confirm Starting Point in External DiCE XAI XL File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59c0cd-50c5-44fd-b708-0d712d5d3ed7",
   "metadata": {},
   "source": [
    "The code below acts so that for each dataframe in the list just created the following actions are carried out;\n",
    "\n",
    "Check if an XAI results XL spreadsheet called 'DiCE_XAI_Metrics_Experiments.xls' exists;\n",
    "\n",
    "If not create an empty XL spreadsheet with the name 'DiCE_XAI_Metrics_Experiments.xls', and then define a variable called ‘Sample’ with an integer value of 1 and print the value of 'Sample' to output.\n",
    "\n",
    "If and XL spreadsheet called 'DiCE_XAI_Metrics_Experiments.xls' does exist, then read the entries in the spreadsheet in the first column named ‘Sample Number’ and create a variable in this Python program named ‘Sample’ that is one integer value higher than the highest integer number column named ‘Sample Number’ in the XL, and print this value of 'Sample' to output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb95e75e-8d4d-42dc-a25f-e0ce42c77352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential number as an identifier for each DataFrame\n",
    "list_df = {f'df_{i + 1}': list_df[i] for i in range(len(list_df))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4926fc-a9be-470c-9800-d02119b19693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the XAI results spreadsheet\n",
    "DiCE_xai_file_path = 'DICE_XAI_Metrics_Experiments.xlsx'  # Stored locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e07ff-561e-4fac-a72e-8ed278d26fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Function to update or create the spreadsheet and determine the 'Sample' number\n",
    "# Process each dataframe in 'list_df'\n",
    "sample = return_next_sample_number_to_process(list_df, DiCE_xai_file_path, \"DiCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51313328-ce40-49a7-b37b-7050d5df95c7",
   "metadata": {},
   "source": [
    "## Select Next Dataframe to Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c401e-7e72-43e0-bec6-dea206049d6c",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "\n",
    "\t\n",
    "Extend the Python code so that the code reads in the dataframe from 'list df' that corresponds to the integer value in the \n",
    "variable named ‘Sample’. \n",
    "\n",
    "Assign this dataframe the name 'df_Selected_from_List'.\n",
    "\n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc07df0-568c-4e32-90ee-7872ea22deea",
   "metadata": {},
   "source": [
    "### Initialize Dataframe to Capture Re-start Point as None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da99ff6-1854-4c2d-9aa5-a45069926310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize df_Selected_from_List as None\n",
    "df_Selected_from_List = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96ba17-61f1-4647-be35-e3a564adcf54",
   "metadata": {},
   "source": [
    "### Extract test data block to restart XAI metrics process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a0528-e7dd-4d7b-9ec5-472f5931e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_from_List, key = select_restart_testdata_block(df_Selected_from_List, \n",
    "                                                           list_df, \n",
    "                                                           DiCE_xai_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf4186-8096-4a14-82dd-1a35927af230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no DataFrame is selected (e.g., if 'Sample' exceeds the number of DataFrames in list_df)\n",
    "if 'df_Selected_from_List' not in locals():\n",
    "    print(\"No DataFrame selected. The 'Sample' number may exceed the number of DataFrames in list_df.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b17f0-e4ac-4258-adc2-3ac722ff7c51",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15688ab9-4523-4174-9f9a-57e23c3865f0",
   "metadata": {},
   "source": [
    "## Generate XAI Metrics from Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f5b2d6-6ad0-4bed-abca-c49a2f175636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Selected_from_List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33466803-bcbc-4ead-a00c-0c24a539c701",
   "metadata": {},
   "source": [
    "### Generate DiCE Counterfactuals for the Test Data Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b706b01a-a2c5-47d8-a050-b6782e62f308",
   "metadata": {},
   "source": [
    "#### Pre-Process Values for Data Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889ec58-f784-4d85-b47e-d45ea4e88228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_from_List.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a8cf7-2106-4f00-9043-8e43b306d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_Selected_from_List.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6952b1-9304-4cd7-bd1c-6a2d0be18ab0",
   "metadata": {},
   "source": [
    "#### Scale the feature values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38bb80-fdbd-4deb-ab8b-9672a7c38613",
   "metadata": {},
   "source": [
    "Call Scaling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d979a72-7066-4d94-a169-2ec4f86bee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'X_test' is a numpy array and you have a list of the original column names\n",
    "original_feature_names = [col for col in df_downsampled_loaded.columns if col != 'Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b4ab4-f5ed-4626-8bda-44eba1323e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the feature inputs so that they work with the SHAP generation processs\n",
    "#df_Selected_Scaled_Data_from_List = scale_feature_inputs(df_Selected_from_List, \n",
    "#                                                         original_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873352b4-8870-44ec-b7f5-7e9130675f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_Scaled_Data_from_List = df_Selected_from_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38db6a-ada1-494a-b486-f831c0bf682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_Scaled_Data_from_List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575d8da-c912-4fd3-a993-b538643a1648",
   "metadata": {},
   "source": [
    "#### Review DiCE Data Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89546c71-e192-47f8-a2f0-e23492ed35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_Scaled_Data_from_List['OnlinePOSCount.cnt.day.present']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1135e-5366-4563-8656-468ffc4f6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_counterfactuals_for_instances(df, num_instances=20, sLabel='Fraud'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a43ac-1e07-45b9-b339-612b4ee9b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled_loaded_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27222873-daa8-4695-9249-51bc1917aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_Scaled_Data_from_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae65d6-ca6d-4827-b859-e33343e20828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_values_outside_range(df_downsampled_loaded_scaled, df_Selected_Scaled_Data_from_List):\n",
    "    # Get the range of values in 'OnlinePOSCount.cnt.day.present' of df_downsampled_loaded_scaled\n",
    "    min_value = df_downsampled_loaded_scaled['OnlinePOSCount.cnt.day.present'].min()\n",
    "    max_value = df_downsampled_loaded_scaled['OnlinePOSCount.cnt.day.present'].max()\n",
    "\n",
    "    print(f\"Range in df_downsampled_loaded_scaled: {min_value} to {max_value}\")\n",
    "    \n",
    "    \n",
    "    min_value2 = df_Selected_Scaled_Data_from_List['OnlinePOSCount.cnt.day.present'].min()\n",
    "    max_value2 = df_Selected_Scaled_Data_from_List['OnlinePOSCount.cnt.day.present'].max()\n",
    "\n",
    "    print(f\"Range in df_Selected_Scaled_Data_from_List: {min_value2} to {max_value2}\")\n",
    "\n",
    "    # Iterate through df_Selected_Scaled_Data_from_List and print values outside the range\n",
    "    for value in df_Selected_Scaled_Data_from_List['OnlinePOSCount.cnt.day.present']:\n",
    "        if value < min_value or value > max_value:\n",
    "            print(f\"Value outside range: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e32a8b4-8b4a-4109-b545-eba9e5d17936",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_values_outside_range(df_downsampled_loaded_scaled, df_Selected_Scaled_Data_from_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013aea43-76a5-4cf7-abcf-91b00726247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d2 = dice_ml.Data(dataframe=df_downsampled_loaded_scaled, \n",
    "#                 continuous_features=cc_continuous_features_list, \n",
    "#                 outcome_name='Fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5526259-ca09-4368-ad4d-6f2f20a864a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = dice_ml.Data(dataframe=df_TestData, \n",
    "                 continuous_features=cc_continuous_features_list, \n",
    "                 outcome_name='Fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dcbf89-d8b1-46b1-8d1c-056058ecb1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = dice_ml.Model(model=loaded_model, backend='TF2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e25ddb-3159-4116-bb65-ff9dc97dbaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_block = dice_ml.Dice(d2, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7508c47e-d1d8-453f-9930-18942694a614",
   "metadata": {},
   "source": [
    "#### DiCE Data Pre-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e754723-ca43-476a-b9c9-c63244819e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set option to display all columns (you can adjust the number as needed)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202166ad-e90d-4a1b-8534-fca89b1983ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "query_instances_block = df_Selected_Scaled_Data_from_List.iloc[0:3].drop('Fraud', axis=1)  # Taking the first instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ce50d9-a36b-4694-91e6-80c48f9fc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactuals_block = exp_block.generate_counterfactuals(query_instances_block, total_CFs=1, desired_class=\"opposite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bef597-6cfd-4061-a6c9-1960c747c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactuals_block.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d615c6-01c8-46a8-919e-7b4885157247",
   "metadata": {},
   "source": [
    "Extract the label values from the data block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e84b9-84bc-4e6c-9bac-25084524bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df = df_Selected_Scaled_Data_from_List['Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce5892-95f8-453c-81b1-f93733708b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4361ed5-c686-4ff3-90ef-4489cb5e5503",
   "metadata": {},
   "source": [
    "#### Get DiCE Values for Data Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961ead9-bc59-43e3-9467-c7159418ca00",
   "metadata": {},
   "source": [
    "Set limit value (for debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205effa-460a-45dd-a9ce-8047e7d99af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 'zero' limit value will process the entire data block\n",
    "limit_data_block_rows = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5705c7f-670c-4d21-a2be-bba70a2f7d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DiCE, exec_time_Dice = generate_counterfactuals_for_instances(df_Selected_Scaled_Data_from_List,\n",
    "                                                                      exp_block,\n",
    "                                                                      limit_data_block_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d363f9-080b-4d1f-bd1f-17a7c19ded04",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df_DiCE, cf_df_DiCE = results_DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ffdce0-34e1-4428-a59a-be4111428c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0bb1d-f647-4784-bd2a-fbc0e57863e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cf_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60310d-28d9-4bf1-8c4d-06d59d2d6bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df_DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178fa1ba-7a8f-4aef-bf4f-3f0aa256aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df_DiCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb813e-06b4-419b-8072-9b2e3fc5cd34",
   "metadata": {},
   "source": [
    "### Generate Identity Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d2b81-5722-4bdb-aa35-11194697deb3",
   "metadata": {},
   "source": [
    "#### Pre-Process Identity Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39472f5c-8ab5-4c80-b0b3-30fdb5374e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df_DiCE, cf_df_DiCE = scale_feature_xai_inputs(original_df_DiCE, \n",
    "#                                                        cf_df_DiCE, \n",
    "#                                                        df_downsampled_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84abfac4-6b23-4e45-aa86-c38a7da45fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830478dd-68a0-44d6-b524-630c2f13f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df_DiCE = scaler.fit_transform(original_df_DiCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad44bcc-6442-4092-b1e6-d8792d8c3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_df_DiCE = scaler.fit_transform(cf_df_DiCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9489c-0a62-4b72-909a-b9f54ec41946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the feature names, including the target variable 'Fraud'\n",
    "#column_names_wDefault = df_downsampled_loaded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737172a4-c5f9-42d4-8ea8-bd602b19b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "#original_df_DiCE = pd.DataFrame(original_df_DiCE, columns=column_names_wDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eddf7f-9241-4426-ad67-370d41937004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_names = df_downsampled_loaded.drop('Fraud', axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cbfb45-3894-47d6-8626-7577185ee32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "#cf_df_DiCE = pd.DataFrame(cf_df_DiCE, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04da81-89e3-4ecf-994a-298ccfb6ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values to float for consistent data type\n",
    "#original_df_DiCE = original_df_DiCE.astype(float)\n",
    "#cf_df_DiCE = cf_df_DiCE.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425351f5-b9f7-42f2-9637-60cb559f628f",
   "metadata": {},
   "source": [
    "#### Run a Basic Test First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62ff400-e847-477c-af3e-bed8cbf99c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two random instances from the DiCE dataframe\n",
    "df_xai_numerical = cf_df_DiCE\n",
    "\n",
    "random_indices = np.random.choice(df_xai_numerical.index, size=2, replace=False)\n",
    "instance_1 = df_xai_numerical.iloc[random_indices[0]]\n",
    "instance_2 = df_xai_numerical.iloc[random_indices[1]]\n",
    "\n",
    "# Compute the Euclidean distance between the selected instances - uses custom project function\n",
    "distance = get_euclidean_distance(instance_1, instance_2)\n",
    "print(f\"Euclidean distance between instance {random_indices[0]} and instance {random_indices[1]}: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814898d-8142-4db5-903e-b2a860fa005b",
   "metadata": {},
   "source": [
    "#### Retrieve Identity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be735948-82d6-4d54-9e11-6fd4937ea958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44cea1c-a34c-4779-8e04-4fc9ded7f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Identity_Metric = get_identity_metric(original_df_DiCE, cf_df_DiCE, \"DiCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ffcd8-481f-4440-865e-7103c831f5ab",
   "metadata": {},
   "source": [
    "#### Display Identity Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b896a9-79bb-4c03-8d9a-e5c2336d503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Ident_Number = \"{:.2f}%\".format(DiCE_Identity_Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ea635-466b-49f6-bbd8-4b6cc59ff59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text(\"DiCE Identity Metric Score: \" + DiCE_Ident_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e9fa75-98e2-49d8-9d38-636cc21e430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Identity\n",
    "XAI_Ident_Metric_1 = DiCE_Identity_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a703fb-4070-4679-81ec-e33993ce4439",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eeb214-60c4-4002-940c-5de662e9b90a",
   "metadata": {},
   "source": [
    "### Generate Stability Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78418da5-c510-4691-9d38-1ea261f1ac72",
   "metadata": {},
   "source": [
    "#### Pre-Processing of Stability Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80816da-3af6-48bd-a973-539fc8a3ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df_DiCE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad420b1-8b6e-4fc4-a65d-c03a27e95d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df_DiCE.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cefa83a-91c4-4f23-bd1f-7884a1fc91ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413c591-6bad-4001-85f5-892cf93f7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b998e-4d44-439e-9cec-9c32a2c36e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('y_test_block_labels_df')\n",
    "print(y_test_block_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd6e089-a2e3-4925-9cfc-8ceee64efd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the label value input to match earlier adjustments in DiCE value creations\n",
    "if limit_data_block_rows > 0:\n",
    "    y_test_block_labels_df = y_test_block_labels_df.iloc[:limit_data_block_rows]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3babb0c8-e8a4-4c9a-b6a1-2aa25ecb7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a3041-59e1-4104-b3b4-14726cadb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the column name 'Fraud'\n",
    "y_test_block_labels_df.columns = ['Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd7957-7ffb-4910-ae88-77709777c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388f66f-0b91-405e-81dd-4ab844004e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df = y_test_block_labels_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6641c4a-024c-4c26-92ce-80f7bddbb7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a2cff-f609-4e0b-9d56-b112aece6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LabelCount = pd.DataFrame(y_test_block_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a23a3-5688-4706-8d68-5eb3fc04622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrence of each unique value in the 'Fraud' column\n",
    "fraud_counts_label = df_LabelCount['Fraud'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Breakdown of 'Fraud' and non-Fraud label records in df_TestData:\")\n",
    "print(fraud_counts_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be8a49-5cc8-4b1e-808b-f02426c23364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the occurrences of each label\n",
    "#label_counts = df['Fraud'].value_counts()\n",
    "\n",
    "# Finding the label with the most entries\n",
    "#largest_label = label_counts.idxmax()\n",
    "largest_label = fraud_counts_label.idxmax()\n",
    "\n",
    "# Assigning it to largest_label_count\n",
    "#largest_label_count = label_counts[largest_label]\n",
    "largest_label_count = fraud_counts_label[largest_label]\n",
    "\n",
    "print(\"Label with most entries:\", largest_label)\n",
    "print(\"Count of this label:\", largest_label_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca56d92-dc51-46f4-ae5a-197fea71547c",
   "metadata": {},
   "source": [
    "#### Retrieve Stability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aedd87-8b2d-4805-b5ec-8fdf24dc0d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DiCE_Stability_Metric = get_stability_metric_y(cf_df_DiCE, \n",
    "#                                               y_test_loaded,\n",
    "#                                               largest_label, \n",
    "#                                               'DiCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798db4ee-8ecf-4c35-bf92-c7654fe0c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Stability_Metric = get_stability_metric_y(cf_df_DiCE, \n",
    "                                               y_test_block_labels_df,\n",
    "                                               largest_label, \n",
    "                                               'DiCE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52184a47-467a-4e00-a62a-dd3bb0a7dd38",
   "metadata": {},
   "source": [
    "#### Display Stability Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a46da7-78d0-4c7e-a7db-e4dddb87a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Stbly_Number = \"{:.2f}%\".format(DiCE_Stability_Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce5972-bc17-4f75-bc81-6f5f9270126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text(\"DiCE Stability Metric Score: \" + DiCE_Stbly_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b48ba-55e6-43fc-b86b-0e502ef4e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Stability\n",
    "XAI_Stability_Metric_2 = DiCE_Stability_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc585d2d-c527-4ea6-8112-bdde6eba93a7",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dfc615-86c7-4a23-8599-ab75a9e544f0",
   "metadata": {},
   "source": [
    "### Generate Seperability Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc51767-213f-4d27-8eed-1cbf84d0f547",
   "metadata": {},
   "source": [
    "#### Retrieve Seperability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da4a82a-9cb0-43ae-ad7d-7924dde0378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649c1a2-17fb-4ed0-9154-dffc5db87c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cf_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52234443-d448-488b-b8e7-ac012398ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df_DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91825fb3-b88e-4d5e-8ca1-ff45f60dafbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df_DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f5b67-b0ed-4ee7-a685-448c98117513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DiCE_Seperability_Metric = get_seperability_metric(original_df_DiCE, cf_df_DiCE, \"DiCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05901dc0-1f92-4865-bfe6-cd6a97de2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Seperability_Metric = get_seperability_metric(original_df_DiCE, \n",
    "                                                   cf_df_DiCE, \n",
    "                                                   \"DiCE\",\n",
    "                                                   0.80, # threshold  #0.51\n",
    "                                                   0.35) # tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f1aad-4b49-4f5f-8fe1-33836e5408ec",
   "metadata": {},
   "source": [
    "#### Display Seperability Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ac778-8b2e-4961-ad3a-c8cdd33aeb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Seperability_Number = \"{:.2f}%\".format(DiCE_Seperability_Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f3e4e-b637-41f0-8495-18d2c883f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text(\"DiCE Seperability Metric Score: \" + DiCE_Seperability_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0a327-9313-4195-a6bd-b43b23e21c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Seperability\n",
    "XAI_Seperability_Metric_3 = DiCE_Seperability_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030f93b-d42e-467d-a769-e6034147a5ba",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47827762-a542-4892-ab08-51eede136d21",
   "metadata": {},
   "source": [
    "### Generate Similarity Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc84d3c-ee0a-444d-bcfd-80547861456e",
   "metadata": {},
   "source": [
    "#### Retrieve Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4a422-0073-4187-9373-28387baaf796",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fc93f-87a7-4288-b601-d69d675fbf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cf_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5153e9f-eecf-444c-a04c-0ebbeca3891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Similarity_Metric = get_similarity_metric(original_df_DiCE, \n",
    "                                               cf_df_DiCE, \n",
    "                                               \"DiCE\", \n",
    "                                               use_dbscan=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc95d7-53aa-4176-a525-83ebbfd94200",
   "metadata": {},
   "source": [
    "#### Display Similarity Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b8721-406a-4e73-9d01-bb7f31b217ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Similarity_Number = \"{:6.2f}\".format(DiCE_Similarity_Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711991f5-4b7a-4e07-9b94-0497b2c7b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text(\"DiCE Similarity Metric Value: \" + DiCE_Similarity_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053a627-b7af-4ac6-8ab2-353e907d8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Similarity\n",
    "XAI_Similarity_Metric_4 = DiCE_Similarity_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf878bce-ed36-40db-af9d-2022887117ca",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6fb224-c5f0-446e-aba9-98896a7a0172",
   "metadata": {},
   "source": [
    "### Display Final Set of Metrics (this run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a7766-4152-4d9a-b6ea-6b80b9942de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(f\"XAI Ident Metric 1: {XAI_Ident_Metric_1}\")\n",
    "print(f\"XAI Stability Metric 2: {XAI_Stability_Metric_2}\")\n",
    "print(f\"XAI Seperability Metric 1: {XAI_Seperability_Metric_3}\")\n",
    "print(f\"XAI Similarity Metric 1: {XAI_Similarity_Metric_4}\")\n",
    "print(f\"XAI Time Metric 5: {exec_time_Dice} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8becf255-8d5a-4b49-9478-5a17f67a217e",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f1e7aa-bae3-47ab-99a8-50fd148ef0a6",
   "metadata": {},
   "source": [
    "## Write Out Metrics to XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70489556-5140-4d91-a641-87cdbc849cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_Selected_from_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155ff20-f112-4872-9d68-9fbe6038dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_xai_Metrics_to_XL(DiCE_xai_file_path, \n",
    "                        sample, \n",
    "                        DiCE_Identity_Metric, \n",
    "                        DiCE_Stability_Metric, \n",
    "                        DiCE_Seperability_Metric, \n",
    "                        DiCE_Similarity_Metric, \n",
    "                        exec_time_Dice, \n",
    "                        df_Selected_from_List,\n",
    "                        \"DiCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1ff69-af7f-42cc-894d-7fc8e454e342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
