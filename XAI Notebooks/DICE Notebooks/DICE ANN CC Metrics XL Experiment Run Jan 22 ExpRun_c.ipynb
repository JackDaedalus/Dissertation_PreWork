{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6a486b-7a72-4691-8f57-260d79c5b234",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Disseration Experiment 6k\n",
    "# Generate DICE Output (Credit Card Fraud) - Experiment Jan 22Â¶\n",
    "Ciaran Finnegan January 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf1fe4-b634-4d96-9d71-ca3c511196b2",
   "metadata": {},
   "source": [
    "# Import Libraries + Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3199cb23-d506-4576-8658-9c9e3ea1db33",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8884cf21-2d0d-457b-b738-8a9280059051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Display libraries\n",
    "from IPython.display import display, HTML\n",
    "from prettytable import PrettyTable\n",
    "import raiutils\n",
    "from raiutils.exceptions import UserConfigValidationException\n",
    "\n",
    "\n",
    "# Import necessary libraries for DICE explainer\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers  # helper functions\n",
    "\n",
    "\n",
    "# Import necessary libraries for NN Modelling\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "\n",
    "# Libraries required for metrics calculations\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "# Libraries for Supplementary Model Evaluation\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "# Classifier training (not used for explainability)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Libraries used in Experiment Creation of XL Output Metrics\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee2b9bdf-7e9b-4392-ab7a-201fa73a72d3",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "026204c6-487b-493b-ba0e-d183313deb9b",
   "metadata": {},
   "source": [
    "Dataset Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe990ca-e2ae-4ff2-8717-6b44611d9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./DS_Visualisation_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5be5fc-a8db-4305-b5f8-922019057b68",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79b526b8-52c3-442b-9c13-9318d7601e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./XAI_Metrics_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e5c28d-0c07-4f7e-ab3a-3234ef4bd08c",
   "metadata": {},
   "source": [
    "Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec1dbd5-037d-47ec-9c04-2b27599a3048",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./DS_Model_Build_Evaluation_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "812d5845-3804-409e-89e6-6407aed98ef8",
   "metadata": {},
   "source": [
    "Track Experiment Result Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b5de81e-14ce-47f6-9dde-d6a90cfb0ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./XAI_Experiment_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e54ff1-79b6-4f97-9052-bcd154126e1c",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72daa4d5-8380-4e9d-b7f0-8c4fabd0deb6",
   "metadata": {},
   "source": [
    "A Neural Network Model has been created in another Kubeflow Notebook and is being used in all the XAI experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aedb8365-904e-44f9-b985-d702de36d30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('ccfraud_model')  # If saved as SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b737778-ebbe-46ac-9fd8-9616323b6b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_loaded, y_test_loaded, X_train_loaded, y_train_loaded, df_downsampled_loaded, dfCatCols = load_CC_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9200d15-6454-45ff-a613-13bfd0d9ba20",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_loaded.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1947f79-7359-4e69-ad5e-e5db6f9059c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_train_loaded.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7515a5-f146-4af2-abb4-94c621418ad5",
   "metadata": {},
   "source": [
    "## Re-Display Model Peformance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb898c44-e5c5-499c-8045-1f09edc4441c",
   "metadata": {},
   "source": [
    "For illustration, the evualtion metrics of the NN model will be repeated here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f81b105-1170-4978-ad30-7c6b6d35fe0e",
   "metadata": {},
   "source": [
    "### Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78dd2944-6747-4263-8bd7-bff2033d12b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the StandardScaler\n",
    "scale_loaded = StandardScaler()   \n",
    "scale_loaded_wf = StandardScaler()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a128b83-7995-4362-a443-65a83b065a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data\n",
    "X_train_loaded_scaled = scale_loaded.fit_transform(X_train_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d056a3-a743-494f-8360-a9b80616f61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data\n",
    "X_test_loaded_scaled  = scale_loaded.transform(X_test_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7316252-28e5-45cb-af67-346f27086a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the 'Fraud' column and store it in a new dataframe\n",
    "df_fraudlabel = df_downsampled_loaded[['Fraud']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7320330a-e8c2-4dbb-8e5f-2684e7803c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraudlabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a444b1ae-93de-40b2-b085-22c5d2f40c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the 'Fraud' column from the original dataframe\n",
    "#df_downsampled_loaded = df_downsampled_loaded.drop(columns=['Fraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa8640f6-a280-4aa4-87f4-f017473c71cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the transform() function on the remaining dataframe\n",
    "#df_downsampled_loaded_scaled = scale_loaded.transform(df_downsampled_loaded)\n",
    "df_downsampled_loaded_scaled = scale_loaded_wf.fit_transform(df_downsampled_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f406f7b6-ce52-42af-b6b3-1bc6bceb4870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the scaled array back to a DataFrame\n",
    "df_downsampled_loaded_scaled = pd.DataFrame(df_downsampled_loaded_scaled, \n",
    "                                            columns=df_downsampled_loaded.columns,\n",
    "                                            index=df_downsampled_loaded.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f83ab11e-d4ca-41f1-82ac-a443eeac33e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate the scaled dataframe with the 'Fraud' column\n",
    "#df_downsampled_loaded_scaled = pd.concat([df_downsampled_loaded_scaled, df_fraudlabel], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae415b7-0f04-43f0-acd9-447d47e8af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled_loaded_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe30fbb-7c68-4cdd-8b76-ef69ecdd5881",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled_loaded_scaled['Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac63791-c7e9-4ea4-be40-d94e52498495",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_loaded = display_model_metrics_tabular(loaded_model, X_test_loaded_scaled, y_test_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3423934-e8fa-4142-a988-cd3ff29875f8",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f111fcdb-8143-4cc9-9f70-16459e90880b",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_confusion_matrix(y_test_loaded, y_pred_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8072535-5a1e-4a6b-be40-58e0e85cf8d9",
   "metadata": {},
   "source": [
    "# Generate DiCE Values (Examples Instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f678e7-85d0-4884-aa8c-520c45f55a45",
   "metadata": {},
   "source": [
    "## Generate the Counterfactuals"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15dfe2d9-adf3-40e1-ab50-38723985bf54",
   "metadata": {},
   "source": [
    "### Use Tensor Flow - Prepare DiCE parameters - CC Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c2dd0d-f937-458f-b043-d79f99c0d7bb",
   "metadata": {},
   "source": [
    "#### Read External File Containing list of Continous Features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "806068de-f7cf-4f69-b1c7-cce897f84034",
   "metadata": {},
   "source": [
    "An analysis, external to this Notebook, has taken place to identify the set of continous features that will be use din this experiment to generate Counterfactual values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b97a86-998a-41eb-8b74-439bbc4b2c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in file with list of continuous features for which to generate the DiCE Counterfactuals\n",
    "def read_cc_features(file_path):\n",
    "    # Read the CSV file\n",
    "    data = pd.read_csv(file_path)\n",
    "\n",
    "    # Filter the data where Rank is 39 or between 41 and 53 (inclusive)\n",
    "    filtered_data = data[(data['RANK'] == 39) | ((data['RANK'] >= 41) & (data['RANK'] <= 55))]\n",
    "\n",
    "    # Extract the 'Feature' column values and return them as a list\n",
    "    feature_list = filtered_data['FEATURE'].tolist()\n",
    "    return feature_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725100a8-dfc1-4ffa-9f67-02c06d49d34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume the file is in the same directory as Notebook\n",
    "file_path = 'Select_CC_Fraud_Features_v1_1.csv'\n",
    "cc_continuous_features_list = read_cc_features(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f345bda-b12b-4b8d-92de-f0be85ff9f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display List of continous features loaded from external XL file.\n",
    "#cc_continuous_features_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72b6253a-8ae0-419c-9e1a-af9e7580358b",
   "metadata": {},
   "source": [
    "#### Verify DiCE Counterfactual Data Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99111b08-aeb2-426c-87cf-a66f07002a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the list of columns from loaded dataframe\n",
    "#original_cols_names = df_downsampled_loaded.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d17d86-e27e-48f5-bcbb-5dab5006d83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "#df_downsampled_loaded_scaled = pd.DataFrame(df_downsampled_loaded_scaled, columns=original_cols_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6131c5d4-82e2-47c7-bc43-13f7fb7e3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled_loaded_scaled['Fraud']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e98b8e-6754-459b-b08e-ad1be9d26c12",
   "metadata": {},
   "source": [
    "#### Build DiCE Counterfactual Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424a29c0-cda4-42bb-8504-ba81f13a17d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "# Define the data for DiCE based on your DataFrame\n",
    "d = dice_ml.Data(dataframe=df_downsampled_loaded_scaled, \n",
    "                 continuous_features=cc_continuous_features_list, \n",
    "                 outcome_name='Fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3246ef5-99c1-4aec-8e5e-ac658541bcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the backend as TensorFlow and link the model\n",
    "m = dice_ml.Model(model=loaded_model, backend='TF2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24ee56-d3fe-44f5-85e6-f9d51010fc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize DiCE\n",
    "exp = dice_ml.Dice(d, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d78a16-7aa8-42f9-8405-ecd27f2e1b04",
   "metadata": {},
   "source": [
    "#### Example 1: Sample DiCE Counterfactual example (x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43f2fd9a-3f65-4fd2-b6e4-869944fb945c",
   "metadata": {},
   "source": [
    "The code below provides examples of generated counterfactuals. In the first two examples, for each instance entry the code has generated five counterfactuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a496200-75b8-4e7a-9d27-bd849acba23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'X_test' is a numpy array and you have a list of the original column names\n",
    "#feature_names = [col for col in df_downsampled_loaded.columns if col != 'Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc859e-8542-4ca7-8392-5ce5ae6c515c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "#X_test_loaded_scaled = pd.DataFrame(X_test_loaded_scaled, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e65961-7fc4-45ba-8b4b-691b08805324",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "#query_instances = X_test_loaded_scaled.iloc[0:2]#.drop('Fraud', axis=1)  # Taking the first two instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ceb22a3-dbc9-47e1-ae98-9c11f6537a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change query instances to match the instances you are interested in\n",
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "query_instances = df_downsampled_loaded_scaled.iloc[0:2].drop('Fraud', axis=1)  # Taking the first two instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f230c6-2d7b-4e42-a4f1-8bb29a2cb35a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactual explanations\n",
    "counterfactuals = exp.generate_counterfactuals(query_instances, total_CFs=5, desired_class=\"opposite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fcfaa9-fd18-4168-9743-38a54affacfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the counterfactual explanations\n",
    "counterfactuals.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4097bdc-9336-4dae-bb31-1ab5c394aede",
   "metadata": {},
   "source": [
    "Reverse Scale the ouptut to make the visualisation more meaningful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97be4a4-ee2f-4b41-aa84-f486e7ce61bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Retrieve counterfactuals as a DataFrame\n",
    "cf_df = counterfactuals.cf_examples_list[0].final_cfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31fe82ee-128f-439f-88e8-a360974d7a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Inverse scale the counterfactuals\n",
    "#cf_df_inverse_scaled = pd.DataFrame(scaler.inverse_transform(cf_df), columns=cf_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1eaf7a-3093-4c20-be5f-5e818889e217",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Inverse scale the counterfactuals\n",
    "cf_df_inverse_scaled = pd.DataFrame(scale_loaded_wf.inverse_transform(cf_df), columns=cf_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44071e3e-da91-41fb-a124-42c0d191a364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Visualize the inverse scaled counterfactuals\n",
    "# You can now use cf_df_inverse_scaled for a more interpretable visualization\n",
    "# For example, you can print it or use any visualization library like matplotlib, seaborn, etc.\n",
    "#print(cf_df_inverse_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c121124-da30-405f-907b-14e3fdab3eff",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4abf6863-ec2e-49ab-b1a0-bca59217d9fd",
   "metadata": {},
   "source": [
    "#### Example 2: Counterfactual - Highlighted Display"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5478d0ba-8151-4680-9f0a-2f67d56aead6",
   "metadata": {},
   "source": [
    "This example uses a display routine to improve the visual highlighting of the counterfactuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6119a25-7da1-48ad-b840-58f60b667dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactuals\n",
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "query_instance = df_downsampled_loaded_scaled.iloc[0:1].drop('Fraud', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09bc9f47-1942-4a23-91df-75abc3fcbb43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate counterfactuals\n",
    "dice_exp = exp.generate_counterfactuals(query_instance, total_CFs=5, desired_class=\"opposite\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f7d270-4730-47e4-b426-c6543567eef9",
   "metadata": {},
   "source": [
    "#### Visualize Counterfactuals (Single Set) - No Highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7acf9c-018e-4244-b901-11e1c7eaa3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dice_exp.visualize_as_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "108f0511-2a3e-47a8-95cf-3087d84875c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_and_visualize_counterfactuals(query_instance, scaler, exp, total_CFs=5, desired_class=\"opposite\"):\n",
    "    # Generate counterfactuals\n",
    "    dice_expv = exp.generate_counterfactuals(query_instance, total_CFs=total_CFs, desired_class=desired_class)\n",
    "    \n",
    "    # Extract counterfactuals as a DataFrame\n",
    "    cf_dfv = dice_expv.cf_examples_list[0].final_cfs_df\n",
    "    \n",
    "    # Inverse scale the counterfactuals\n",
    "    cf_df_inverse_scaled = pd.DataFrame(scaler.inverse_transform(cf_dfv), columns=cf_dfv.columns)\n",
    "    \n",
    "    # Visualize the inverse scaled counterfactuals\n",
    "    return cf_df_inverse_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89bd1ad-15b5-44b0-8ed5-72171427956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage\n",
    "query_instance = df_downsampled_loaded_scaled.iloc[0:1].drop('Fraud', axis=1)\n",
    "#inverse_scaled_cfs = generate_and_visualize_counterfactuals(query_instance, scale_loaded, exp)\n",
    "#print(inverse_scaled_cfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49b70a10-3a75-4c66-b5c6-15195fd8945b",
   "metadata": {},
   "source": [
    "#### Visualize Counterfactuals (Single Set) - With Highlights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a448bc39-fcc0-4ccb-9583-3d91cd3223fc",
   "metadata": {},
   "source": [
    "##### Create Display Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9007cfb4-047c-4ff2-9cbc-92e368937822",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_differences(query_instance, counterfactuals_df):\n",
    "    \"\"\"\n",
    "    Compares a query instance (as a Series) with counterfactual instances in a DataFrame.\n",
    "    \n",
    "    Args:\n",
    "    - query_instance (pd.Series): The original data instance.\n",
    "    - counterfactuals_df (pd.DataFrame): DataFrame containing counterfactual instances.\n",
    "    \n",
    "    Returns:\n",
    "    - A styled DataFrame where:\n",
    "        * The original instance is highlighted entirely.\n",
    "        * Cells with differences in counterfactuals are highlighted.\n",
    "    \"\"\"\n",
    "    # Convert query_instance to DataFrame and concatenate with counterfactuals_df\n",
    "    combined_df = pd.concat([query_instance.to_frame().T, counterfactuals_df], axis=0).reset_index(drop=True)\n",
    "    \n",
    "    def highlight_cells(row):\n",
    "        \"\"\"Helper function to apply the styling.\"\"\"\n",
    "        if row.name == 0:  # If it's the original instance\n",
    "            return ['background-color: lightblue' for _ in row.index]\n",
    "        \n",
    "        # For counterfactual rows\n",
    "        colors = []\n",
    "        for col in row.index:\n",
    "            original_value = query_instance[col]\n",
    "            cf_value = row[col]\n",
    "            \n",
    "            # Convert to the same data type if they are different\n",
    "            if type(original_value) != type(cf_value):\n",
    "                try:\n",
    "                    original_value = type(cf_value)(original_value)\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        cf_value = type(original_value)(cf_value)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "            \n",
    "            # Handle float comparisons with a small tolerance\n",
    "            if isinstance(original_value, float) and isinstance(cf_value, float):\n",
    "                if abs(original_value - cf_value) < 1e-9:\n",
    "                    colors.append('')\n",
    "                else:\n",
    "                    colors.append('background-color: yellow')\n",
    "            elif original_value != cf_value:\n",
    "                colors.append('background-color: yellow')\n",
    "            else:\n",
    "                colors.append('')\n",
    "        return colors\n",
    "    \n",
    "    styled_df = combined_df.style.apply(highlight_cells, axis=1)\n",
    "    return styled_df\n",
    "\n",
    "# This refined version of the function should handle potential data type mismatches better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f6aa2a2-def6-4f69-9074-d7d30fd3bb90",
   "metadata": {},
   "source": [
    "##### Display Differences - with Highlights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e04381-77c1-40e0-bbbd-38c084487e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Extract counterfactuals to a DataFrame\n",
    "your_actual_counterfactuals_df = dice_exp.cf_examples_list[0].final_cfs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4414fec3-1d5e-4ab7-a7df-03474a3030ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inverse scale the counterfactuals\n",
    "actual_counterfactuals_df_inverse_scaled = pd.DataFrame(scale_loaded_wf.inverse_transform(your_actual_counterfactuals_df), \n",
    "                                                        columns=your_actual_counterfactuals_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6c1410-a4cd-44a2-965b-0f18998e85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#your_actual_counterfactuals_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d9e621-15f2-453d-966a-e57549619abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_instance_series = df_downsampled_loaded.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3c1e60-f834-4040-84ba-c8315741437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#styled_result = highlight_differences(query_instance_series, your_actual_counterfactuals_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d413696a-5ad0-4d43-8d2d-a4bb9149b204",
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_result = highlight_differences(query_instance_series, actual_counterfactuals_df_inverse_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bdc8ea0-7328-4ca1-9532-09d00f0d9f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualize differences\n",
    "display(styled_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafb90b7-d202-4c0e-9091-e9bb718189e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df_downsampled_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34348f69-df3d-4241-8ad2-550387e2339f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlight_differences_modified(query_instance, counterfactuals_df):\n",
    "    # Adjust 'Fraud' value in counterfactuals_df\n",
    "    fraud_value = 1 if query_instance['Fraud'] == 0 else 0\n",
    "    counterfactuals_df['Fraud'] = fraud_value\n",
    "\n",
    "    # Convert query_instance to DataFrame and concatenate with counterfactuals_df\n",
    "    combined_df = pd.concat([query_instance.to_frame().T, counterfactuals_df], axis=0).reset_index(drop=True)\n",
    "\n",
    "    def highlight_cells(row):\n",
    "        \n",
    "        \"\"\"Helper function to apply the styling.\"\"\"\n",
    "        if row.name == 0:  # If it's the original instance\n",
    "            return ['background-color: lightblue' for _ in row.index]\n",
    "        \n",
    "        # Styling function\n",
    "        colors = []\n",
    "        for col in row.index:\n",
    "            original_value = query_instance[col]\n",
    "            cf_value = row[col]\n",
    "\n",
    "            # Convert to the same data type if they are different\n",
    "            if type(original_value) != type(cf_value):\n",
    "                try:\n",
    "                    original_value = type(cf_value)(original_value)\n",
    "                except ValueError:\n",
    "                    try:\n",
    "                        cf_value = type(original_value)(cf_value)\n",
    "                    except ValueError:\n",
    "                        pass\n",
    "\n",
    "            # Handle float comparisons with increased tolerance\n",
    "            if isinstance(original_value, float) and isinstance(cf_value, float):\n",
    "                if abs(original_value - cf_value) <= 1.00:\n",
    "                    colors.append('')\n",
    "                else:\n",
    "                    colors.append('background-color: yellow')\n",
    "            elif original_value != cf_value:\n",
    "                colors.append('background-color: yellow')\n",
    "            else:\n",
    "                colors.append('')\n",
    "        return colors\n",
    "\n",
    "    styled_df = combined_df.style.apply(highlight_cells, axis=1).format(\"{:.2f}\", na_rep=\"-\")\n",
    "    return styled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4939551-2aad-4577-b3d4-68a305e59201",
   "metadata": {},
   "outputs": [],
   "source": [
    "styled_result = highlight_differences_modified(query_instance_series, actual_counterfactuals_df_inverse_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41abbf2a-e4d0-4b86-812b-4719a2b17e41",
   "metadata": {},
   "source": [
    "Display DiCE Counterfactuals for Instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "576cb07b-ec76-46d8-b64a-8af80d063b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Visualize differences\n",
    "display(styled_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b94da-d0a4-4bf0-9d6d-f43a20d4df56",
   "metadata": {},
   "source": [
    "# Prepare DiCE Input for Metric Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5733b8-aad3-4ae2-a491-4f3322d37801",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def generate_counterfactuals_for_instances(df, exp_block, num_instances=20, sLabel='Fraud'):\n",
    "    \"\"\"\n",
    "    Generate counterfactual explanations for a specified number of instances from a dataframe.\n",
    "    \n",
    "    Args:\n",
    "    - df (pd.DataFrame): The dataframe containing the original instances.\n",
    "    - num_instances (int): The number of instances for which to generate counterfactuals.\n",
    "    \n",
    "    Returns:\n",
    "    - original_instances_df (pd.DataFrame): DataFrame containing the original instances.\n",
    "    - counterfactuals_df (pd.DataFrame): DataFrame containing the counterfactual explanations.\n",
    "    \"\"\"\n",
    "    # Prepare an empty dataframe for counterfactuals\n",
    "    counterfactuals_list = []\n",
    "    \n",
    "    #######################\n",
    "    \n",
    "    # Select a subset of the data for explanation (first nn instances)\n",
    "    if num_instances > 0:\n",
    "        \n",
    "        #instances_to_explain = data_features.iloc[:limit, :]#25\n",
    "        # Select the first 'num_instances' from the dataframe\n",
    "        original_instances_df = df.head(num_instances)\n",
    "    \n",
    "    else:\n",
    "        # Select all input feature for which to generate SHAP values\n",
    "        original_instances_df = df\n",
    "        \n",
    "    #######################\n",
    "    \n",
    "    # Select the first 'num_instances' from the dataframe\n",
    "    #original_instances_df = df.head(num_instances)\n",
    "    \n",
    "    for index, instance in original_instances_df.iterrows():\n",
    "    #for _, instance in original_instances_df.iterrows():\n",
    "        # Convert the instance to DataFrame\n",
    "        \n",
    "        print(f\"Processing row number: {index}\")\n",
    "        #print(instance['OnlinePOSCount.cnt.day.present'])\n",
    "        \n",
    "        instance_df = instance.drop(sLabel).to_frame().T\n",
    "        #instance_df = instance.drop('default').to_frame().T\n",
    "        #instance_df = instance.to_frame().T\n",
    "        \n",
    "        print(f'instance_df[OnlinePOSCount.cnt.day.present]: {instance_df[\"OnlinePOSCount.cnt.day.present\"]}')\n",
    "\n",
    "        # Generate counterfactual for the instance\n",
    "        # dice_exp = exp.generate_counterfactuals(instance_df, total_CFs=1, desired_class=\"opposite\")\n",
    "        #exp_block\n",
    "        dice_exp_block = exp_block.generate_counterfactuals(instance_df, total_CFs=1, desired_class=\"opposite\")\n",
    "        \n",
    "        \n",
    "        # Extract the counterfactual to a DataFrame\n",
    "        cf_df = dice_exp_block.cf_examples_list[0].final_cfs_df.drop(sLabel, axis=1)\n",
    "        #cf_df = dice_exp.cf_examples_list[0].final_cfs_df.drop('default', axis=1)\n",
    "        #cf_df = dice_exp.cf_examples_list[0].final_cfs_df\n",
    "        \n",
    "        # Append the counterfactual to the list\n",
    "        counterfactuals_list.append(cf_df.iloc[0])\n",
    "    \n",
    "    # Reset Indexes of Output for alignment into XAI Metrics functions\n",
    "    original_instances_df = original_instances_df.reset_index(drop=True)\n",
    "    counterfactuals_df = pd.DataFrame(counterfactuals_list).reset_index(drop=True)\n",
    "    \n",
    "    return original_instances_df, counterfactuals_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e15ce31c-f80b-4d5f-a666-48e31fc11d65",
   "metadata": {},
   "source": [
    "# XAI Experiments - Metrics Capture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e223116-befa-4ea5-a1ef-082a8cb2b53d",
   "metadata": {},
   "source": [
    "## Suppress Warnings to clean up output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f98fd8-7e35-439d-aec6-60a5bb7c32d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10cf93e6-78ed-4595-855a-6f187d2d226f",
   "metadata": {},
   "source": [
    "## Break out Model Test Data into a list of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bb03a92-2859-4b38-b8cc-909280d10c3d",
   "metadata": {},
   "source": [
    "### Create Test Data for Experiment Input"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5594c5d4-5cf1-4726-9a5f-ca605de1ef9f",
   "metadata": {},
   "source": [
    "Step 1: Ensure 'X_test' and 'y_test' Are DataFrames with Proper Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093213b5-d0f5-4627-b12d-accf13fc894a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'X_test' is a numpy array and you have a list of the original column names\n",
    "original_feature_names = [col for col in df_downsampled_loaded.columns if col != 'Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321a2fe5-e796-4494-9d5f-9b2396c60fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure X_test_loaded has the correct column names (if necessary)\n",
    "#X_test_loaded.columns = original_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38db3134-edb5-4bcd-8ea7-a5a9fc7891aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "# Convert NumPy array to DataFrame\n",
    "X_test_loaded_scaled = pd.DataFrame(X_test_loaded_scaled, columns=original_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90caafcb-7f63-4052-9708-2e03dee27b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine X_test_loaded and y_test into a single DataFrame\n",
    "df_TestData = pd.concat([X_test_loaded_scaled, y_test_loaded], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763f88cb-f47c-40c1-910d-78699a001cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_TestData"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a884210-9f03-42e8-9f9e-ffc6d7bda9b3",
   "metadata": {},
   "source": [
    "### Split the DataFrame into 20 consecutive smaller DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e4c912-6b45-49be-a9c0-f69ef18a329a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into 20 consecutive smaller DataFrames\n",
    "split_size, list_df = split_TestData_into_nn_Blocks(df_TestData, num_splits = 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdc4097-c44e-40a3-869d-852bea9509f4",
   "metadata": {},
   "source": [
    "### Check Label Count for Stability Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a06e73-02a2-46f2-aa74-445c51fa82e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrence of each unique value in the 'Fraud' column\n",
    "fraud_counts = df_TestData['Fraud'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Breakdown of 'Fraud' and non-Fraud label records in df_TestData:\")\n",
    "print(fraud_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd669b36-5b95-4a5a-bd6c-75c5f50d370e",
   "metadata": {},
   "source": [
    "### Add a routine to check output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a06a179-82ce-4975-9879-02e1a762cf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display starting points in the first nn sub dataframes\n",
    "startBlockDisplay(df_TestData, split_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8ab48bd-aa44-458c-892e-aeb8be308876",
   "metadata": {},
   "source": [
    "## Confirm Starting Point in External DiCE XAI XL File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d59c0cd-50c5-44fd-b708-0d712d5d3ed7",
   "metadata": {},
   "source": [
    "The code below acts so that for each dataframe in the list just created the following actions are carried out;\n",
    "\n",
    "Check if an XAI results XL spreadsheet called 'DiCE_XAI_Metrics_Experiments.xls' exists;\n",
    "\n",
    "If not create an empty XL spreadsheet with the name 'DiCE_XAI_Metrics_Experiments.xls', and then define a variable called âSampleâ with an integer value of 1 and print the value of 'Sample' to output.\n",
    "\n",
    "If and XL spreadsheet called 'DiCE_XAI_Metrics_Experiments.xls' does exist, then read the entries in the spreadsheet in the first column named âSample Numberâ and create a variable in this Python program named âSampleâ that is one integer value higher than the highest integer number column named âSample Numberâ in the XL, and print this value of 'Sample' to output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb95e75e-8d4d-42dc-a25f-e0ce42c77352",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential number as an identifier for each DataFrame\n",
    "list_df = {f'df_{i + 1}': list_df[i] for i in range(len(list_df))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4926fc-a9be-470c-9800-d02119b19693",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the XAI results spreadsheet\n",
    "DiCE_xai_file_path = 'DICE_XAI_Metrics_Experiments.xlsx'  # Stored locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "265e07ff-561e-4fac-a72e-8ed278d26fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Function to update or create the spreadsheet and determine the 'Sample' number\n",
    "# Process each dataframe in 'list_df'\n",
    "sample = return_next_sample_number_to_process(list_df, DiCE_xai_file_path, \"DiCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51313328-ce40-49a7-b37b-7050d5df95c7",
   "metadata": {},
   "source": [
    "## Select Next Dataframe to Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409c401e-7e72-43e0-bec6-dea206049d6c",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "\n",
    "\t\n",
    "Extend the Python code so that the code reads in the dataframe from 'list df' that corresponds to the integer value in the \n",
    "variable named âSampleâ. \n",
    "\n",
    "Assign this dataframe the name 'df_Selected_from_List'.\n",
    "\n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fc07df0-568c-4e32-90ee-7872ea22deea",
   "metadata": {},
   "source": [
    "### Initialize Dataframe to Capture Re-start Point as None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da99ff6-1854-4c2d-9aa5-a45069926310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize df_Selected_from_List as None\n",
    "df_Selected_from_List = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb96ba17-61f1-4647-be35-e3a564adcf54",
   "metadata": {},
   "source": [
    "### Extract test data block to restart XAI metrics process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b04a0528-e7dd-4d7b-9ec5-472f5931e328",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_from_List, key = select_restart_testdata_block(df_Selected_from_List, \n",
    "                                                           list_df, \n",
    "                                                           DiCE_xai_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bbf4186-8096-4a14-82dd-1a35927af230",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no DataFrame is selected (e.g., if 'Sample' exceeds the number of DataFrames in list_df)\n",
    "if 'df_Selected_from_List' not in locals():\n",
    "    print(\"No DataFrame selected. The 'Sample' number may exceed the number of DataFrames in list_df.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1b17f0-e4ac-4258-adc2-3ac722ff7c51",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15688ab9-4523-4174-9f9a-57e23c3865f0",
   "metadata": {},
   "source": [
    "## Generate XAI Metrics from Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f5b2d6-6ad0-4bed-abca-c49a2f175636",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_Selected_from_List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33466803-bcbc-4ead-a00c-0c24a539c701",
   "metadata": {},
   "source": [
    "### Generate DiCE Counterfactuals for the Test Data Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b706b01a-a2c5-47d8-a050-b6782e62f308",
   "metadata": {},
   "source": [
    "#### Pre-Process Values for Data Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3889ec58-f784-4d85-b47e-d45ea4e88228",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_from_List.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a8cf7-2106-4f00-9043-8e43b306d090",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_Selected_from_List.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6952b1-9304-4cd7-bd1c-6a2d0be18ab0",
   "metadata": {},
   "source": [
    "#### Scale the feature values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d38bb80-fdbd-4deb-ab8b-9672a7c38613",
   "metadata": {},
   "source": [
    "Call Scaling Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d979a72-7066-4d94-a169-2ec4f86bee30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'X_test' is a numpy array and you have a list of the original column names\n",
    "original_feature_names = [col for col in df_downsampled_loaded.columns if col != 'Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f78b4ab4-f5ed-4626-8bda-44eba1323e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the feature inputs so that they work with the SHAP generation processs\n",
    "#df_Selected_Scaled_Data_from_List = scale_feature_inputs(df_Selected_from_List, \n",
    "#                                                         original_feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873352b4-8870-44ec-b7f5-7e9130675f42",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_Scaled_Data_from_List = df_Selected_from_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da38db6a-ada1-494a-b486-f831c0bf682a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_Scaled_Data_from_List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9575d8da-c912-4fd3-a993-b538643a1648",
   "metadata": {},
   "source": [
    "#### Review DiCE Data Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89546c71-e192-47f8-a2f0-e23492ed35bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_Scaled_Data_from_List['OnlinePOSCount.cnt.day.present']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc1135e-5366-4563-8656-468ffc4f6d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_counterfactuals_for_instances(df, num_instances=20, sLabel='Fraud'):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1a43ac-1e07-45b9-b339-612b4ee9b329",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_downsampled_loaded_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27222873-daa8-4695-9249-51bc1917aedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_Scaled_Data_from_List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ae65d6-ca6d-4827-b859-e33343e20828",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_values_outside_range(df_downsampled_loaded_scaled, df_Selected_Scaled_Data_from_List):\n",
    "    # Get the range of values in 'OnlinePOSCount.cnt.day.present' of df_downsampled_loaded_scaled\n",
    "    min_value = df_downsampled_loaded_scaled['OnlinePOSCount.cnt.day.present'].min()\n",
    "    max_value = df_downsampled_loaded_scaled['OnlinePOSCount.cnt.day.present'].max()\n",
    "\n",
    "    print(f\"Range in df_downsampled_loaded_scaled: {min_value} to {max_value}\")\n",
    "    \n",
    "    \n",
    "    min_value2 = df_Selected_Scaled_Data_from_List['OnlinePOSCount.cnt.day.present'].min()\n",
    "    max_value2 = df_Selected_Scaled_Data_from_List['OnlinePOSCount.cnt.day.present'].max()\n",
    "\n",
    "    print(f\"Range in df_Selected_Scaled_Data_from_List: {min_value2} to {max_value2}\")\n",
    "\n",
    "    # Iterate through df_Selected_Scaled_Data_from_List and print values outside the range\n",
    "    for value in df_Selected_Scaled_Data_from_List['OnlinePOSCount.cnt.day.present']:\n",
    "        if value < min_value or value > max_value:\n",
    "            print(f\"Value outside range: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e32a8b4-8b4a-4109-b545-eba9e5d17936",
   "metadata": {},
   "outputs": [],
   "source": [
    "check_values_outside_range(df_downsampled_loaded_scaled, df_Selected_Scaled_Data_from_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "013aea43-76a5-4cf7-abcf-91b00726247d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#d2 = dice_ml.Data(dataframe=df_downsampled_loaded_scaled, \n",
    "#                 continuous_features=cc_continuous_features_list, \n",
    "#                 outcome_name='Fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5526259-ca09-4368-ad4d-6f2f20a864a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "d2 = dice_ml.Data(dataframe=df_TestData, \n",
    "                 continuous_features=cc_continuous_features_list, \n",
    "                 outcome_name='Fraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32dcbf89-d8b1-46b1-8d1c-056058ecb1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "m2 = dice_ml.Model(model=loaded_model, backend='TF2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e25ddb-3159-4116-bb65-ff9dc97dbaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_block = dice_ml.Dice(d2, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7508c47e-d1d8-453f-9930-18942694a614",
   "metadata": {},
   "source": [
    "#### DiCE Data Pre-Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e754723-ca43-476a-b9c9-c63244819e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set option to display all columns (you can adjust the number as needed)\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202166ad-e90d-4a1b-8534-fca89b1983ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan 18th - use new loaded model and data - SCALED\n",
    "query_instances_block = df_Selected_Scaled_Data_from_List.iloc[0:3].drop('Fraud', axis=1)  # Taking the first instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ce50d9-a36b-4694-91e6-80c48f9fc501",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactuals_block = exp_block.generate_counterfactuals(query_instances_block, total_CFs=1, desired_class=\"opposite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bef597-6cfd-4061-a6c9-1960c747c0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "counterfactuals_block.visualize_as_dataframe(show_only_changes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d615c6-01c8-46a8-919e-7b4885157247",
   "metadata": {},
   "source": [
    "Extract the label values from the data block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583e84b9-84bc-4e6c-9bac-25084524bb47",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df = df_Selected_Scaled_Data_from_List['Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ce5892-95f8-453c-81b1-f93733708b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4361ed5-c686-4ff3-90ef-4489cb5e5503",
   "metadata": {},
   "source": [
    "#### Get DiCE Values for Data Block"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7961ead9-bc59-43e3-9467-c7159418ca00",
   "metadata": {},
   "source": [
    "Set limit value (for debugging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b205effa-460a-45dd-a9ce-8047e7d99af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A 'zero' limit value will process the entire data block\n",
    "limit_data_block_rows = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5705c7f-670c-4d21-a2be-bba70a2f7d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_DiCE, exec_time_Dice = generate_counterfactuals_for_instances(df_Selected_Scaled_Data_from_List,\n",
    "                                                                      exp_block,\n",
    "                                                                      limit_data_block_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0d363f9-080b-4d1f-bd1f-17a7c19ded04",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df_DiCE, cf_df_DiCE = results_DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72ffdce0-34e1-4428-a59a-be4111428c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c0bb1d-f647-4784-bd2a-fbc0e57863e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cf_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab60310d-28d9-4bf1-8c4d-06d59d2d6bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df_DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178fa1ba-7a8f-4aef-bf4f-3f0aa256aeee",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df_DiCE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddeb813e-06b4-419b-8072-9b2e3fc5cd34",
   "metadata": {},
   "source": [
    "### Generate Identity Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5d2b81-5722-4bdb-aa35-11194697deb3",
   "metadata": {},
   "source": [
    "#### Pre-Process Identity Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39472f5c-8ab5-4c80-b0b3-30fdb5374e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df_DiCE, cf_df_DiCE = scale_feature_xai_inputs(original_df_DiCE, \n",
    "#                                                        cf_df_DiCE, \n",
    "#                                                        df_downsampled_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84abfac4-6b23-4e45-aa86-c38a7da45fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "830478dd-68a0-44d6-b524-630c2f13f7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#original_df_DiCE = scaler.fit_transform(original_df_DiCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad44bcc-6442-4092-b1e6-d8792d8c3698",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cf_df_DiCE = scaler.fit_transform(cf_df_DiCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f9489c-0a62-4b72-909a-b9f54ec41946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the feature names, including the target variable 'Fraud'\n",
    "#column_names_wDefault = df_downsampled_loaded.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737172a4-c5f9-42d4-8ea8-bd602b19b24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "#original_df_DiCE = pd.DataFrame(original_df_DiCE, columns=column_names_wDefault)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35eddf7f-9241-4426-ad67-370d41937004",
   "metadata": {},
   "outputs": [],
   "source": [
    "#column_names = df_downsampled_loaded.drop('Fraud', axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cbfb45-3894-47d6-8626-7577185ee32e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "#cf_df_DiCE = pd.DataFrame(cf_df_DiCE, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b04da81-89e3-4ecf-994a-298ccfb6ef5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all values to float for consistent data type\n",
    "#original_df_DiCE = original_df_DiCE.astype(float)\n",
    "#cf_df_DiCE = cf_df_DiCE.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "425351f5-b9f7-42f2-9637-60cb559f628f",
   "metadata": {},
   "source": [
    "#### Run a Basic Test First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c62ff400-e847-477c-af3e-bed8cbf99c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two random instances from the DiCE dataframe\n",
    "df_xai_numerical = cf_df_DiCE\n",
    "\n",
    "random_indices = np.random.choice(df_xai_numerical.index, size=2, replace=False)\n",
    "instance_1 = df_xai_numerical.iloc[random_indices[0]]\n",
    "instance_2 = df_xai_numerical.iloc[random_indices[1]]\n",
    "\n",
    "# Compute the Euclidean distance between the selected instances - uses custom project function\n",
    "distance = get_euclidean_distance(instance_1, instance_2)\n",
    "print(f\"Euclidean distance between instance {random_indices[0]} and instance {random_indices[1]}: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2814898d-8142-4db5-903e-b2a860fa005b",
   "metadata": {},
   "source": [
    "#### Retrieve Identity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be735948-82d6-4d54-9e11-6fd4937ea958",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44cea1c-a34c-4779-8e04-4fc9ded7f2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Identity_Metric = get_identity_metric(original_df_DiCE, cf_df_DiCE, \"DiCE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb6ffcd8-481f-4440-865e-7103c831f5ab",
   "metadata": {},
   "source": [
    "#### Display Identity Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b896a9-79bb-4c03-8d9a-e5c2336d503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Ident_Number = \"{:.2f}%\".format(DiCE_Identity_Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87ea635-466b-49f6-bbd8-4b6cc59ff59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text(\"DiCE Identity Metric Score: \" + DiCE_Ident_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e9fa75-98e2-49d8-9d38-636cc21e430d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Identity\n",
    "XAI_Ident_Metric_1 = DiCE_Identity_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a703fb-4070-4679-81ec-e33993ce4439",
   "metadata": {},
   "source": [
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71eeb214-60c4-4002-940c-5de662e9b90a",
   "metadata": {},
   "source": [
    "### Generate Stability Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78418da5-c510-4691-9d38-1ea261f1ac72",
   "metadata": {},
   "source": [
    "#### Pre-Processing of Stability Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80816da-3af6-48bd-a973-539fc8a3ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df_DiCE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad420b1-8b6e-4fc4-a65d-c03a27e95d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df_DiCE.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cefa83a-91c4-4f23-bd1f-7884a1fc91ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_loaded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7413c591-6bad-4001-85f5-892cf93f7c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d7b998e-4d44-439e-9cec-9c32a2c36e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('y_test_block_labels_df')\n",
    "print(y_test_block_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd6e089-a2e3-4925-9cfc-8ceee64efd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the label value input to match earlier adjustments in DiCE value creations\n",
    "if limit_data_block_rows > 0:\n",
    "    y_test_block_labels_df = y_test_block_labels_df.iloc[:limit_data_block_rows]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3babb0c8-e8a4-4c9a-b6a1-2aa25ecb7576",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "400a3041-59e1-4104-b3b4-14726cadb27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the column name 'Fraud'\n",
    "y_test_block_labels_df.columns = ['Fraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fd7957-7ffb-4910-ae88-77709777c291",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7388f66f-0b91-405e-81dd-4ab844004e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df = y_test_block_labels_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6641c4a-024c-4c26-92ce-80f7bddbb7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_block_labels_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622a2cff-f609-4e0b-9d56-b112aece6758",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_LabelCount = pd.DataFrame(y_test_block_labels_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f6a23a3-5688-4706-8d68-5eb3fc04622c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrence of each unique value in the 'Fraud' column\n",
    "fraud_counts_label = df_LabelCount['Fraud'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Breakdown of 'Fraud' and non-Fraud label records in df_TestData:\")\n",
    "print(fraud_counts_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4be8a49-5cc8-4b1e-808b-f02426c23364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counting the occurrences of each label\n",
    "#label_counts = df['Fraud'].value_counts()\n",
    "\n",
    "# Finding the label with the most entries\n",
    "#largest_label = label_counts.idxmax()\n",
    "largest_label = fraud_counts_label.idxmax()\n",
    "\n",
    "# Assigning it to largest_label_count\n",
    "#largest_label_count = label_counts[largest_label]\n",
    "largest_label_count = fraud_counts_label[largest_label]\n",
    "\n",
    "print(\"Label with most entries:\", largest_label)\n",
    "print(\"Count of this label:\", largest_label_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ca56d92-dc51-46f4-ae5a-197fea71547c",
   "metadata": {},
   "source": [
    "#### Retrieve Stability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aedd87-8b2d-4805-b5ec-8fdf24dc0d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DiCE_Stability_Metric = get_stability_metric_y(cf_df_DiCE, \n",
    "#                                               y_test_loaded,\n",
    "#                                               largest_label, \n",
    "#                                               'DiCE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798db4ee-8ecf-4c35-bf92-c7654fe0c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Stability_Metric = get_stability_metric_y(cf_df_DiCE, \n",
    "                                               y_test_block_labels_df,\n",
    "                                               largest_label, \n",
    "                                               'DiCE')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52184a47-467a-4e00-a62a-dd3bb0a7dd38",
   "metadata": {},
   "source": [
    "#### Display Stability Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a46da7-78d0-4c7e-a7db-e4dddb87a084",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Stbly_Number = \"{:.2f}%\".format(DiCE_Stability_Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ce5972-bc17-4f75-bc81-6f5f9270126a",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text(\"DiCE Stability Metric Score: \" + DiCE_Stbly_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9b48ba-55e6-43fc-b86b-0e502ef4e7e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Stability\n",
    "XAI_Stability_Metric_2 = DiCE_Stability_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc585d2d-c527-4ea6-8112-bdde6eba93a7",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63dfc615-86c7-4a23-8599-ab75a9e544f0",
   "metadata": {},
   "source": [
    "### Generate Seperability Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc51767-213f-4d27-8eed-1cbf84d0f547",
   "metadata": {},
   "source": [
    "#### Retrieve Seperability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da4a82a-9cb0-43ae-ad7d-7924dde0378f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5649c1a2-17fb-4ed0-9154-dffc5db87c30",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cf_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52234443-d448-488b-b8e7-ac012398ce47",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_df_DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91825fb3-b88e-4d5e-8ca1-ff45f60dafbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cf_df_DiCE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f5b67-b0ed-4ee7-a685-448c98117513",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DiCE_Seperability_Metric = get_seperability_metric(original_df_DiCE, cf_df_DiCE, \"DiCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05901dc0-1f92-4865-bfe6-cd6a97de2d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Seperability_Metric = get_seperability_metric(original_df_DiCE, \n",
    "                                                   cf_df_DiCE, \n",
    "                                                   \"DiCE\",\n",
    "                                                   0.80, # threshold  #0.51\n",
    "                                                   0.35) # tolerance)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458f1aad-4b49-4f5f-8fe1-33836e5408ec",
   "metadata": {},
   "source": [
    "#### Display Seperability Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ac778-8b2e-4961-ad3a-c8cdd33aeb77",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Seperability_Number = \"{:.2f}%\".format(DiCE_Seperability_Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9f3e4e-b637-41f0-8495-18d2c883f475",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text(\"DiCE Seperability Metric Score: \" + DiCE_Seperability_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7f0a327-9313-4195-a6bd-b43b23e21c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Seperability\n",
    "XAI_Seperability_Metric_3 = DiCE_Seperability_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4030f93b-d42e-467d-a769-e6034147a5ba",
   "metadata": {},
   "source": [
    "----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47827762-a542-4892-ab08-51eede136d21",
   "metadata": {},
   "source": [
    "### Generate Similarity Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebc84d3c-ee0a-444d-bcfd-80547861456e",
   "metadata": {},
   "source": [
    "#### Retrieve Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4a422-0073-4187-9373-28387baaf796",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c8fc93f-87a7-4288-b601-d69d675fbf55",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cf_df_DiCE.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5153e9f-eecf-444c-a04c-0ebbeca3891b",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Similarity_Metric = get_similarity_metric(original_df_DiCE, \n",
    "                                               cf_df_DiCE, \n",
    "                                               \"DiCE\", \n",
    "                                               use_dbscan=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09bc95d7-53aa-4176-a525-83ebbfd94200",
   "metadata": {},
   "source": [
    "#### Display Similarity Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b8721-406a-4e73-9d01-bb7f31b217ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "DiCE_Similarity_Number = \"{:6.2f}\".format(DiCE_Similarity_Metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711991f5-4b7a-4e07-9b94-0497b2c7b475",
   "metadata": {},
   "outputs": [],
   "source": [
    "display_text(\"DiCE Similarity Metric Value: \" + DiCE_Similarity_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c053a627-b7af-4ac6-8ab2-353e907d8e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Similarity\n",
    "XAI_Similarity_Metric_4 = DiCE_Similarity_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf878bce-ed36-40db-af9d-2022887117ca",
   "metadata": {},
   "source": [
    "-------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6fb224-c5f0-446e-aba9-98896a7a0172",
   "metadata": {},
   "source": [
    "### Display Final Set of Metrics (this run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181a7766-4152-4d9a-b6ea-6b80b9942de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(f\"XAI Ident Metric 1: {XAI_Ident_Metric_1}\")\n",
    "print(f\"XAI Stability Metric 2: {XAI_Stability_Metric_2}\")\n",
    "print(f\"XAI Seperability Metric 1: {XAI_Seperability_Metric_3}\")\n",
    "print(f\"XAI Similarity Metric 1: {XAI_Similarity_Metric_4}\")\n",
    "print(f\"XAI Time Metric 5: {exec_time_Dice} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8becf255-8d5a-4b49-9478-5a17f67a217e",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f1e7aa-bae3-47ab-99a8-50fd148ef0a6",
   "metadata": {},
   "source": [
    "## Write Out Metrics to XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70489556-5140-4d91-a641-87cdbc849cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type(df_Selected_from_List))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2155ff20-f112-4872-9d68-9fbe6038dce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_xai_Metrics_to_XL(DiCE_xai_file_path, \n",
    "                        sample, \n",
    "                        DiCE_Identity_Metric, \n",
    "                        DiCE_Stability_Metric, \n",
    "                        DiCE_Seperability_Metric, \n",
    "                        DiCE_Similarity_Metric, \n",
    "                        exec_time_Dice, \n",
    "                        df_Selected_from_List,\n",
    "                        \"DiCE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1ff69-af7f-42cc-894d-7fc8e454e342",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
