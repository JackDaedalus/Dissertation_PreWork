{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6e6a486b-7a72-4691-8f57-260d79c5b234",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Disseration Experiment 5h\n",
    "# Generate ANCHOR Output (Credit Default) January EightÂ¶\n",
    "Ciaran Finnegan January 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "326467c2-f2e4-41ef-8448-5175667109fd",
   "metadata": {},
   "source": [
    "# Import Libraries + Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03b5aa-a7a9-41a1-bb6a-56644cc198d8",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8884cf21-2d0d-457b-b738-8a9280059051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Display libraries\n",
    "from IPython.display import display, HTML\n",
    "from prettytable import PrettyTable\n",
    "\n",
    "# Import necessary libraries for ANN model building\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Import necessary library for ANCHOR explainer\n",
    "import alibi\n",
    "from alibi.explainers import AnchorTabular\n",
    "#import anchor\n",
    "from anchor import anchor_tabular\n",
    "\n",
    "# Libraries required for metrics calculations\n",
    "from scipy.spatial import distance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import warnings\n",
    "\n",
    "# Compute additional evaluation metrics\n",
    "import sklearn.metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Classifier training (not used for explainability)\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Additional display libraires\n",
    "import contextlib\n",
    "import sys\n",
    "from contextlib import contextmanager\n",
    "\n",
    "# Libraries used in Experiment Creation of XL Output Metrics\n",
    "import os\n",
    "import time\n",
    "import random\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d7cdb61-08f0-4ff4-88b4-4b7c8e58f67f",
   "metadata": {},
   "source": [
    "## Custom Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5d4aea3-a604-4dac-955d-36d1e2898297",
   "metadata": {},
   "source": [
    "Dataset Visualisations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aa82e3-eea0-4937-8596-f60dc62fb4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./DS_Visualisation_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129a56c4-5a07-4363-be32-2636409d57d2",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21eee71a-d183-45d4-a9c6-113a1b6be4f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./XAI_Metrics_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd556264-212b-4fd5-9231-9315bb5aaa82",
   "metadata": {},
   "source": [
    "Model Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17372074-9e8a-45c0-a176-50ecffaa7c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./DS_Model_Build_Evaluation_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d0dd94-f3cb-4d99-909b-d43bb79bc5fa",
   "metadata": {},
   "source": [
    "Track Experiment Result Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f87bd84-e352-4c62-8c92-faccaa452ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./XAI_Experiment_Functions.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3919da-8422-4fc0-af8f-244466926beb",
   "metadata": {},
   "source": [
    "------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7f5037-d2de-467b-a6c9-f349aa02ff6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_file_to_load = 'credit_default_data.csv'\n",
    "df = pd.read_csv(ds_file_to_load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9299a2c1-af6f-44aa-a71e-bac546b32f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the threshold for missing values\n",
    "threshold = 0.75 * len(df)\n",
    "\n",
    "# Identify columns with missing values greater than the threshold\n",
    "missing_columns = df.columns[df.isnull().sum() > threshold]\n",
    "\n",
    "# Print the columns with more than 75% missing values\n",
    "print(\"Columns with more than 75% missing values:\", missing_columns)\n",
    "\n",
    "# Drop columns with missing values greater than the threshold\n",
    "df = df.drop(columns=missing_columns)\n",
    "\n",
    "# Save or continue processing with columns removed that had high volumes of missing data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86654757-2644-4c90-aa82-7c3a8e192bab",
   "metadata": {},
   "source": [
    "## Categorical Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6218545b-cfc6-4801-a6bd-890d8183d5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of categorical columns\n",
    "cat_cols = ['SEX', 'EDUCATION', 'MARRIAGE', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea71ce08-645a-4728-981a-14def4345050",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode categorical variables\n",
    "df_encoded = pd.get_dummies(df, columns=cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dafa59ad-d33e-433a-aab3-ea3b7f26e5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the distribution of the target variable\n",
    "target_distribution = df_encoded['default'].value_counts()\n",
    "\n",
    "target_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b153cd-d751-42ea-a9b4-fcabb15f6cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the majority and minority classes\n",
    "df_majority = df_encoded[df_encoded['default'] == 0]\n",
    "df_minority = df_encoded[df_encoded['default'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce058168-bf75-4069-b3ad-e30624bf8c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downsample the majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                   replace=False, \n",
    "                                   n_samples=target_distribution[1], \n",
    "                                   random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162cbf28-d3c1-42ea-8ff3-76ad732a616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the downsampled majority class with the minority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a4ac2a-924e-446a-aed9-81f73f9ded0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle the dataset to mix the data points\n",
    "df_downsampled = df_downsampled.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913bbf66-8c2a-40ca-b57c-bee98333dc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the distribution of the target variable in the downsampled dataset\n",
    "df_downsampled['default'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fad4d198-0c4d-40b2-b576-a1deefa708ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the features and target variable\n",
    "X = df_downsampled.drop('default', axis=1)\n",
    "y = df_downsampled['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418a5d2c-37ad-4242-87bf-93a7cf1c8885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into training and testing sets\n",
    "X_train_downsampled, X_test_downsampled, y_train_downsampled, y_test_downsampled = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d58d2df-a65b-4174-ac51-7d18f9d5592d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset Indexes\n",
    "X_train_downsampled = X_train_downsampled.reset_index(drop=True)\n",
    "X_test_downsampled = X_test_downsampled.reset_index(drop=True)\n",
    "\n",
    "y_train_downsampled = y_train_downsampled.reset_index(drop=True)\n",
    "y_test_downsampled = y_test_downsampled.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d613136f-ec24-4a28-b501-83cb0a1a27e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_downsampled, X_test_downsampled = scale_the_features(X_train_downsampled, X_test_downsampled, df_downsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2018ca08-fb2f-4f44-8fc9-b3ae578b48f5",
   "metadata": {},
   "source": [
    "# Build Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "407376f6-c1f3-4d97-bb63-a3346a1b31fa",
   "metadata": {},
   "source": [
    "## Set Up Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edc6153-a8a2-4d83-bcac-f9a9f40e4e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53175934-1164-4f6c-85d1-278547bf3ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building the model\n",
    "model = models.Sequential([\n",
    "    layers.Dense(64, activation='relu', input_shape=(X_train_downsampled.shape[1],)),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(64, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c17b306-c7d8-4aa9-9ca9-b47d9bf8ef72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be10cb6f-9e35-484c-97d8-5e30c73f463b",
   "metadata": {},
   "source": [
    "## Build Neural Network (w/TensorFlow/Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bb2f40d-3153-45b7-af92-65a62cf30d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "history = model.fit(X_train_downsampled, y_train_downsampled, epochs=15, batch_size=32, validation_split=0.2, verbose=1)\n",
    "print(\"Model trained successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219e8334-6afb-43d7-9f06-ef6eb7197751",
   "metadata": {},
   "source": [
    "# Load Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e299520-a7a5-4e59-bc73-c53663190f4e",
   "metadata": {},
   "source": [
    "A Neural Network Model has been created in another Kubeflow Notebook and is being used in all the XAI experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1875efdc-fe77-43c2-a29e-06f85ed1327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = keras.models.load_model('ccfraud_model')  # If saved as SavedModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5647a17-cb58-4ae8-a9cc-4fc9c02aa7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_loaded, y_test_loaded, X_train_loaded, y_train_loaded, df_downsampled_loaded, dfCatCols = load_CC_train_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25966a0d-83c7-4fe2-8692-45a6da32008c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_loaded.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1377e11-b7a8-4ed1-931d-e79ff57e5942",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_loaded.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9179ce5e-430d-44bc-ab4d-5fd8f50365ba",
   "metadata": {},
   "source": [
    "## Re-Display Model Peformance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce39605a-04c0-4918-baae-77fbbdd4fb49",
   "metadata": {},
   "source": [
    "For illustration, the evualtion metrics of the NN model will be repeated here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d38f5bf2-aa60-419d-8799-69dc3dd67864",
   "metadata": {},
   "source": [
    "### Tabular Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32fbd31d-3e76-4e12-907b-6c1406625572",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()   \n",
    "X_test_loaded_scaled = scaler.fit_transform(X_test_loaded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df03e60-ae68-4980-8b54-af4217e87058",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_loaded = display_model_metrics_tabular(loaded_model, X_test_loaded_scaled, y_test_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64028732-147f-422e-a3c2-9e7cad1c9d64",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6735005-c227-455f-ae8b-feebb5448293",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_confusion_matrix(y_test_loaded, y_pred_loaded)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "119542a4-b5a9-44d8-8f61-296092e9ef6b",
   "metadata": {},
   "source": [
    "# Generate ANCHOR Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6a706c-aa38-4dc0-b31f-c685305d13fe",
   "metadata": {},
   "source": [
    "#### Suppress Warnings to clean up output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39feb23-23a9-41a8-b304-2c37bd766ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c813972-0c7d-4b99-84b6-1643ac0c1633",
   "metadata": {},
   "source": [
    "Check layout of X_train_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34511222-42f3-4cf5-a7e2-e2f4d82b3e49",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d0e0ff-0b41-432e-981b-4e4930008bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the feature names, excluding the target variable 'default'\n",
    "column_names = df_downsampled.drop('default', axis=1).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06525ee1-337b-45a0-b9cd-03e435437997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "X_train_downsampled = pd.DataFrame(X_train_downsampled, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45770351-5e28-440d-91b8-a6909b8cf66e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_downsampled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe85a485-037b-42c5-8931-a688baff372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from anchor import anchor_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9858f7eb-0f13-4692-9eb0-a11fae206035",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate the features and the target variable\n",
    "X = df_encoded.drop('default', axis=1)\n",
    "y = df_encoded['default']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e237762-9db2-4fec-8b55-b75dd1b2d7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the explainer\n",
    "explainer = anchor_tabular.AnchorTabularExplainer(\n",
    "    class_names=['Not Default', 'Default'],\n",
    "    feature_names=X.columns.tolist(),\n",
    "    train_data=X_train_downsampled.values,\n",
    "    categorical_names={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8144f9-b6da-4757-80dc-7413f8815474",
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "from contextlib import contextmanager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada52f7-9071-4bae-bcc5-74e9b877c418",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def suppress_stdout():\n",
    "    with open(os.devnull, 'w') as fnull:\n",
    "        with contextlib.redirect_stdout(fnull), contextlib.redirect_stderr(fnull):\n",
    "            yield None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f6ac202-9c5c-4da3-b943-01d34cfbba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_fn(x):\n",
    "    # Ensure x is in batch format\n",
    "    if len(x.shape) == 1:\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "    # Suppress the output of the progress bar\n",
    "    with suppress_stdout():\n",
    "        # Get the model's prediction (probability of the positive class)\n",
    "        probabilities = model.predict(x, verbose=0)\n",
    "    # Convert probabilities to class labels (0 or 1)\n",
    "    labels = (probabilities > 0.5).astype(int)\n",
    "    return labels.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5abc32-c320-4c13-950d-9a2297f85681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert NumPy array to DataFrame\n",
    "X_test_downsampled = pd.DataFrame(X_test_downsampled, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3042541-69c9-47b2-ab15-6c89a731e34b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure that the instance passed to explain_instance is in the correct shape\n",
    "idx = 0\n",
    "instance_to_explain = X_test_downsampled.iloc[idx].values.reshape(1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d296a832-e658-4ecf-bebd-617ac1ebae8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an explanation for the first instance in the test set\n",
    "exp = explainer.explain_instance(instance_to_explain, predict_fn, threshold=0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c65572-e59b-4ad5-bd4a-1323e73b2e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the explanation\n",
    "exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37431d6-bfa9-434e-8042-db7cafe4b409",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_table=True, show_all=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec71b11c-669d-474f-92e9-e3432f40c6ef",
   "metadata": {},
   "source": [
    "#### Pseudocode to Generate Initial ANCHOR Values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8067dd-5f76-4a3d-8b29-41dfd7a2d348",
   "metadata": {},
   "source": [
    "For the RF model built above in Python, select a random sample \n",
    "of 15 instances in the test data, 10 for Class '0' and 5 for \n",
    "Class '1', and generate ANCHOR values as explainers for these  \n",
    "instances in the test dataset.\n",
    "\n",
    "Present these ANCHOR values in an easily understood and pleasant \n",
    "on the eye tabular output format for the Python Kubeflow Notebook\n",
    "in which I am writing my Python code. \n",
    "\n",
    "Create a second tabular format what shows an equally appealing \n",
    "output in my Python Notebook that shows the ANCHOR values and the\n",
    "feature details for each instance on a single row, across which I\n",
    "can scroll.\n",
    "\n",
    "Comment each line of Python code with as much detail as practical. \n",
    "\n",
    "Output the ANCHOR values to a CSV file. Output the feature details \n",
    "for each corresponding instance for which the ANCHOR Values were\n",
    "created in a seperate CSV file.\n",
    "\n",
    "After the code generation provide as much narrative detail \n",
    "as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b262310f-4581-4824-a5d9-bd1115485ec9",
   "metadata": {},
   "source": [
    "##### Further pseudocode..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97e4abb-a81c-4ba1-9a1e-65f4a3707713",
   "metadata": {},
   "source": [
    "Use the AnchorTabular explainer from the alibi library. This explainer provides local explanations for classification models' predictions by identifying a minimal set of conditions (features) in the instance that ensure the model's decision remains unchanged (these conditions are called \"anchors\").\n",
    "\n",
    "The steps:\n",
    "\n",
    "Select a random sample of 15 instances from the test data, 10 from Class '0' and 5 from Class '1'.\n",
    "Set up the AnchorTabular explainer and fit it to the training data.\n",
    "Generate anchor explanations for the selected instances.\n",
    "Present the anchor values in two tabular formats: a summary table and a detailed table.\n",
    "Output the anchor values and feature details to CSV files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f957338-e9a7-4286-80c2-b520879ee036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through the first five instances in the test dataset\n",
    "for idx in range(5):\n",
    "    instance = X_test_downsampled.iloc[idx].values.reshape(1, -1)\n",
    "    print(f\"\\nInstance {idx + 1}:\")\n",
    "    \n",
    "    # Generate an explanation for the instance\n",
    "    exp = explainer.explain_instance(instance, predict_fn, threshold=0.95)\n",
    "    \n",
    "    # Show the explanation in the notebook\n",
    "    exp.show_in_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620f9249-0375-46c9-842b-afe2c335123a",
   "metadata": {},
   "source": [
    "### Create an ANCHOR File Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "908eed01-2b74-4f26-bbe8-39c9b56ae579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the ANCHOR results\n",
    "anchor_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3ced75-3da1-4fb6-a4ea-9dcf2786859e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "anchor_results = []\n",
    "\n",
    "# Loop through the first five instances in the test dataset\n",
    "for idx in range(5):\n",
    "    instance = X_test_downsampled.iloc[idx].values.reshape(1, -1)\n",
    "    # Generate an explanation for the instance\n",
    "    exp = explainer.explain_instance(instance, predict_fn, threshold=0.95)\n",
    "    \n",
    "    # Extract feature importance from the explanation\n",
    "    feature_importance = {}\n",
    "    for condition in exp.names():\n",
    "        # Handle conditions with '='\n",
    "        if '=' in condition:\n",
    "            feature, value = condition.split('=')\n",
    "            feature = feature.strip()\n",
    "            value = float(value.strip())\n",
    "            feature_importance[feature] = ('=', value)\n",
    "        # Handle conditions with '>' or '<'\n",
    "        elif '>' in condition or '<' in condition:\n",
    "            parts = re.split('([><])', condition)\n",
    "            feature, operator, value = [part.strip() for part in parts if part.strip()]\n",
    "            value = float(value)\n",
    "            feature_importance[feature] = (operator, value)\n",
    "        else:\n",
    "            raise ValueError(f\"Unexpected format for ANCHOR explanation: {condition}\")\n",
    "\n",
    "    anchor_results.append(feature_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23140bb-b6cb-45a9-92c7-ed2f15233a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the results\n",
    "df_anchor_results = pd.DataFrame(anchor_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6419ce66-5465-4601-9eef-9555c4129572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the DataFrame\n",
    "print(df_anchor_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f75987bd-cb41-4576-a5d1-1b849b63978a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the DataFrame to a CSV file\n",
    "df_anchor_results.to_csv('anchor_results_ANN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35439af3-1c0f-4c6a-a759-89124fd22e4d",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3016d008-5f44-4e2f-8c16-34c868372354",
   "metadata": {},
   "source": [
    "# Prepare ANCHOR Values for Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58773ba7-9ff6-4231-8b30-e985f99da9fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@timeit\n",
    "def generate_anchors_for_instances(df, num_instances=5):\n",
    "    # Initialize a list to store the ANCHOR results\n",
    "    new_anchor_results = []\n",
    "    feature_instances = []\n",
    "\n",
    "    # Loop through the first five instances in the test dataset\n",
    "    for idx in range(num_instances):\n",
    "        #instance = X_test_downsampled.iloc[idx]\n",
    "        instance = df.iloc[idx]\n",
    "        feature_instances.append(instance)\n",
    "\n",
    "        # Generate an explanation for the instance with a lower threshold\n",
    "        exp = explainer.explain_instance(instance.values.reshape(1, -1), predict_fn, threshold=0.99)\n",
    "\n",
    "        # Check if an explanation was found\n",
    "        if exp is not None:\n",
    "            # Parse the conditions from the explanation and format them\n",
    "            anchor_explanation = []\n",
    "            for condition in exp.names():\n",
    "                if ' > ' in condition or ' < ' in condition:\n",
    "                    feature, relation, value = condition.split(' ')[0], condition.split(' ')[1], condition.split(' ')[2]\n",
    "                    try:\n",
    "                        anchor_explanation.append(f\"'{feature} {relation} {float(value):.2f}'\")\n",
    "                    except ValueError:\n",
    "                        anchor_explanation.append(f\"'{condition}'\")\n",
    "                else:\n",
    "                    anchor_explanation.append(f\"'{condition}'\")\n",
    "\n",
    "            # Convert the list of strings to a single string\n",
    "            anchor_explanation_str = '[' + ', '.join(anchor_explanation) + ']'\n",
    "\n",
    "            # Add the formatted explanation to the results list\n",
    "            new_anchor_results.append(anchor_explanation_str)\n",
    "        else:\n",
    "            new_anchor_results.append(\"['No explanation found']\")\n",
    "\n",
    "    # Create a DataFrame from the results\n",
    "    new_df_anchor_results = pd.DataFrame(new_anchor_results, columns=['Anchor Explanation'])\n",
    "\n",
    "    # Create a DataFrame from the feature instances\n",
    "    df_feature_instances = pd.DataFrame(feature_instances)\n",
    "    \n",
    "    \n",
    "    return df_feature_instances, new_df_anchor_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3948cf4-ae94-4525-bde8-a92c7bcc0772",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_feature_instances, new_df_anchor_results = generate_anchors_for_instances(X_test_downsampled, 5)\n",
    "results, exec_time = generate_anchors_for_instances(X_test_downsampled, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac31c512-9579-4066-bf50-18b90a61c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_instances, new_df_anchor_results = results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e0f1944-8f9d-474f-ae0a-2694119199b6",
   "metadata": {},
   "source": [
    "## Determine Computational Efficiency Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01d51de-b10b-4021-8477-f5c785549499",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display time to generate DiCE explainers\n",
    "print(f\"ANCHORS Execution Time: {exec_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906265d8-c510-404e-b04b-423946e42943",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the DataFrames\n",
    "print(\"Anchor Explanations:\")\n",
    "print(new_df_anchor_results)\n",
    "#print(\"\\nFeature Instances:\")\n",
    "#print(df_feature_instances)\n",
    "\n",
    "# Write the DataFrames to CSV files\n",
    "new_df_anchor_results.to_csv('new_anchor_results5.csv', index=False)\n",
    "df_feature_instances.to_csv('feature_instances5.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81355e6b-81a0-47de-badb-875d6e235551",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_feature_instances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da878039-4fe3-497a-8428-454144d2b3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_anchor_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae91cf1-3078-4538-a8ad-caf40f177f61",
   "metadata": {},
   "source": [
    "## Parse the Anchor Explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e455a5-342c-4bbb-9be7-adf07e283aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdecc84e-401e-46b7-879b-4761dab8ba64",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Step 2: Convert the 'Anchor Explanation' column from a string representation of a list back to an actual list\n",
    "new_df_anchor_results['Anchor Explanation'] = new_df_anchor_results['Anchor Explanation'].apply(ast.literal_eval)\n",
    "\n",
    "# Step 3: Determine the maximum number of conditions in the ANCHOR explanations across all instances\n",
    "max_num_conditions = max(new_df_anchor_results['Anchor Explanation'].apply(len))\n",
    "\n",
    "# Step 4: Initialize a list to store the numerical representations of the ANCHOR explanations\n",
    "numerical_explanations = []\n",
    "\n",
    "# Step 5: Loop through each ANCHOR explanation and convert it to a numerical representation\n",
    "for explanation in new_df_anchor_results['Anchor Explanation']:\n",
    "    numerical_representation = [-1] * len(df_feature_instances.columns) * max_num_conditions\n",
    "    for idx, condition in enumerate(explanation):\n",
    "        # Parse the condition to extract the feature name and value\n",
    "        feature, relation, value = condition.split(' ')[0], condition.split(' ')[1], condition.split(' ')[2]\n",
    "        \n",
    "        # Find the index of the feature in the feature dataframe\n",
    "        feature_idx = df_feature_instances.columns.get_loc(feature)\n",
    "        \n",
    "        # Store the feature index in the numerical representation\n",
    "        numerical_representation[feature_idx * max_num_conditions + idx] = float(value)\n",
    "    numerical_explanations.append(numerical_representation)\n",
    "\n",
    "# Step 6: Create a dataframe from the numerical representations\n",
    "df_anchors_numerical = pd.DataFrame(numerical_explanations)\n",
    "\n",
    "# Display the resulting dataframe\n",
    "print(df_anchors_numerical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1adc6d6-3544-43eb-80e6-950d11936023",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_anchor_exps(new_df_anchor_results):\n",
    "    \n",
    "    # Step 1: Convert the 'Anchor Explanation' column from a string representation of a list back to an actual list\n",
    "    new_df_anchor_results['Anchor Explanation'] = new_df_anchor_results['Anchor Explanation'].apply(ast.literal_eval)\n",
    "\n",
    "    # Step 2: Determine the maximum number of conditions in the ANCHOR explanations across all instances\n",
    "    max_num_conditions = max(new_df_anchor_results['Anchor Explanation'].apply(len))\n",
    "\n",
    "    # Step 3: Initialize a list to store the numerical representations of the ANCHOR explanations\n",
    "    numerical_explanations = []\n",
    "\n",
    "    # Step 4: Loop through each ANCHOR explanation and convert it to a numerical representation\n",
    "    for explanation in new_df_anchor_results['Anchor Explanation']:\n",
    "        numerical_representation = [-1] * len(df_feature_instances.columns) * max_num_conditions\n",
    "        for idx, condition in enumerate(explanation):\n",
    "            # Parse the condition to extract the feature name and value\n",
    "            feature, relation, value = condition.split(' ')[0], condition.split(' ')[1], condition.split(' ')[2]\n",
    "\n",
    "            # Find the index of the feature in the feature dataframe\n",
    "            feature_idx = df_feature_instances.columns.get_loc(feature)\n",
    "\n",
    "            # Store the feature index in the numerical representation\n",
    "            numerical_representation[feature_idx * max_num_conditions + idx] = float(value)\n",
    "        numerical_explanations.append(numerical_representation)\n",
    "\n",
    "    # Step 5: Create a dataframe from the numerical representations\n",
    "    df_anchors_numerical = pd.DataFrame(numerical_explanations)\n",
    "\n",
    "    # Display the resulting dataframe\n",
    "    print(df_anchors_numerical)\n",
    "    \n",
    "    return df_anchors_numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe6ccf1-fcdb-4ab6-a9b6-8d985a56b42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df_anchor_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "168b3603-1b51-44fb-bec2-9649f2b2c8a2",
   "metadata": {},
   "source": [
    "## Display ANCHORS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26960e2-6520-4a42-8e8d-6924aa02182c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of each dataset to understand their structure\n",
    "instance_features_head = df_feature_instances.head()\n",
    "anchor_explanations_head = new_df_anchor_results.head()\n",
    "anchor_explanations_numerical = df_anchors_numerical.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3c1ed8-959c-4a92-a2f9-b6b670be4778",
   "metadata": {},
   "outputs": [],
   "source": [
    "instance_features_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f82eafe-2889-4097-8a0e-09a5c9ecdc70",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_explanations_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60bd68c-ca9e-41cb-ae8a-89c699dbda47",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchor_explanations_numerical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4656447d-1e45-4aee-923e-fea4e1cf58d1",
   "metadata": {},
   "source": [
    "## Generate Outfile for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f2617-a30a-4afd-adf7-cc50712be650",
   "metadata": {},
   "outputs": [],
   "source": [
    "anchors_num_explainers_filepath = \"anchor_numerical_explainers.csv\"\n",
    "\n",
    "anchor_explanations_numerical.to_csv(anchors_num_explainers_filepath, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f0d16df-2e95-47a7-828f-c1caa1c007ff",
   "metadata": {},
   "source": [
    "# Generate XAI Metrics "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1840f4dc-2390-47b9-a047-d8f225bfea9a",
   "metadata": {},
   "source": [
    "## Identity Metric "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd86065-15b6-4d1e-a3ff-5c5db705ed08",
   "metadata": {},
   "source": [
    "#### Run a Basic Test First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72312d8-3ee2-4df6-b213-67e1cf4ca814",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two random instances from the ANCHOR dataframe\n",
    "df_xai_numerical = anchor_explanations_numerical\n",
    "\n",
    "random_indices = np.random.choice(df_xai_numerical.index, size=2, replace=False)\n",
    "instance_1 = df_xai_numerical.iloc[random_indices[0]]\n",
    "instance_2 = df_xai_numerical.iloc[random_indices[1]]\n",
    "\n",
    "# Compute the Euclidean distance between the selected instances - uses custom project function\n",
    "distance = get_euclidean_distance(instance_1, instance_2)\n",
    "print(f\"Euclidean distance between instance {random_indices[0]} and instance {random_indices[1]}: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c369f7d-a6fb-4506-b85a-f994361c2848",
   "metadata": {},
   "source": [
    "#### Retrieve Identity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a546d3f-53cb-41c5-b5ac-cfb441b7de5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0eafbb-ff1d-4df0-ba35-8d8bd4725a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Identity_Metric = get_identity_metric(df_feature_instances, anchor_explanations_numerical, \"ANCHOR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "312b0ada-5676-46de-913f-50bbe5b82a0f",
   "metadata": {},
   "source": [
    "#### Display Identity Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb2ae16-ce65-4605-b51c-665a56d5510f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Identity_Number = \"{:.2f}%\".format(ANCHOR_Identity_Metric)\n",
    "display_text(\"ANCHOR Identity Metric Score: \" + ANCHOR_Identity_Number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "047864c4-2600-405b-b6db-9d1ae6d57db8",
   "metadata": {},
   "source": [
    "## Stability Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a8dd97a-e8ff-4de2-9d27-0e4638db4030",
   "metadata": {},
   "source": [
    "### Invoke Stability Metric Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a2935-fc4d-4485-92a4-90c2b9ead621",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Stability_Metric = get_stability_metric_y(anchor_explanations_numerical, y_test_downsampled, 'ANCHOR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdaf6776-0a63-4b6d-b5a5-33e848749914",
   "metadata": {},
   "source": [
    "#### Display Stability Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d45e85f-faca-42e2-8efe-3db48a005ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Stability_Number = \"{:.2f}%\".format(ANCHOR_Stability_Metric)\n",
    "display_text(\"ANCHOR Stability Metric Score: \" + ANCHOR_Stability_Number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc93a738-a9eb-4e99-aa3c-b04d4840b91c",
   "metadata": {},
   "source": [
    "## Seperability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020429dc-7ba7-4e30-8c65-74d87de2ef9e",
   "metadata": {},
   "source": [
    "### Invoke Seperability Metric Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "499b0b7b-506e-4031-a55f-daf2ddee0188",
   "metadata": {},
   "source": [
    "#### Retrieve Seperability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d0ee5df-706a-473d-969f-82b2163b1eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Seperability_Metric = get_seperability_metric(df_feature_instances, anchor_explanations_numerical, \"ANCHOR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee2f687-4b34-4deb-ace4-f9d1289334a3",
   "metadata": {},
   "source": [
    "#### Display Seperability Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b47c2-ea12-411d-bfe9-9452db0e5e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Seperability_Number = \"{:.2f}%\".format(ANCHOR_Seperability_Metric)\n",
    "display_text(\"ANCHOR Seperability Metric Score: \" + ANCHOR_Seperability_Number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6b373cb-3a90-4d3e-ae80-f2b5c0da541c",
   "metadata": {},
   "source": [
    "## Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "614cb4a5-3d19-41e3-9133-7fc1ed85bec5",
   "metadata": {},
   "source": [
    "### Invoke Similarity Metric Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3067f3f2-f277-4311-a03c-e20cf8ab2b03",
   "metadata": {},
   "source": [
    "#### Retrieve Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a5cccf-414e-4a2b-8b57-753b791a485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Similarity_Metric = get_similarity_metric(df_feature_instances, anchor_explanations_numerical, \"ANCHOR\", \n",
    "                                                 use_dbscan=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbf26d4a-feee-4369-9470-7e90e3ed0048",
   "metadata": {},
   "source": [
    "#### Display Similarity Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb4c913-95c8-415b-a17a-81cd34905f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Similarity_Number = \"{:6.2f}\".format(ANCHOR_Similarity_Metric)\n",
    "display_text(\"ANCHOR Similarity Metric Value: \" + ANCHOR_Similarity_Number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7328d49-c5d1-4a54-b589-39af23ef753d",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8089e3-25a2-4d31-a561-54b320557052",
   "metadata": {},
   "source": [
    "# XAI Experiments - Metrics Capture"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbbfd08-0e71-4e03-9d22-6ca1f60c36c1",
   "metadata": {},
   "source": [
    "## Suppress Warnings to clean up output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779129cb-fe2b-48b2-9f4b-d502bd8c2575",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c06edb9a-6c43-4b40-a58c-55da8fb7109f",
   "metadata": {},
   "source": [
    "## Break out Model Test Data into a list of dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3dc5411-844e-4633-b541-4505316305bf",
   "metadata": {},
   "source": [
    "### Create Test Data for Experiment Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6524d948-928b-400e-a839-4e450e1af6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_feature_names = [col for col in df_downsampled_loaded.columns if col != 'Fraud']\n",
    "\n",
    "# Ensure X_test_loaded has the correct column names (if necessary)\n",
    "X_test_loaded.columns = original_feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a162404-158f-40a1-a3ef-0ddb54ecc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine X_test_loaded and y_test into a single DataFrame\n",
    "df_TestData = pd.concat([X_test_loaded, y_test_loaded], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d18990dd-42e7-42b5-8e1c-a7cc455183fa",
   "metadata": {},
   "source": [
    "### Split the DataFrame into 20 consecutive smaller DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d2c609-8229-4057-a0c9-7e110646843d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the DataFrame into 20 consecutive smaller DataFrames\n",
    "split_size, list_df = split_TestData_into_nn_Blocks(df_TestData, num_splits = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52af9224-634b-4402-bca8-c483dbb24f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the occurrence of each unique value in the 'Fraud' column\n",
    "fraud_counts = df_TestData['Fraud'].value_counts()\n",
    "\n",
    "# Display the counts\n",
    "print(\"Breakdown of 'Fraud' and non-Fraud label records in df_TestData:\")\n",
    "print(fraud_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe0f01a-d8cf-4cc4-a158-8d0f2e234351",
   "metadata": {},
   "source": [
    "### Add a routine to check output values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc91e06-63ae-412a-a2c3-b6d0c789d865",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display starting points in the first nn sub dataframes\n",
    "startBlockDisplay(df_TestData, split_size, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e8f6db-a6ae-4c0b-bc9f-6d9ef74568c7",
   "metadata": {},
   "source": [
    "## Confirm Starting Point in External ANCHORS XAI XL File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b346f0bf-0d71-4a47-9930-f78494b34134",
   "metadata": {},
   "source": [
    "The code below acts so that for each dataframe in the list just created the following actions are carried out;\n",
    "\n",
    "Check if an XAI results XL spreadsheet called 'ANCHOR_XAI_Metrics_Experiments.xls' exists;\n",
    "\n",
    "If not create an empty XL spreadsheet with the name 'ANCHOR_XAI_Metrics_Experiments.xls', and then define a variable called âSampleâ with an integer value of 1 and print the value of 'Sample' to output.\n",
    "\n",
    "If and XL spreadsheet called 'ANCHOR_XAI_Metrics_Experiments.xls' does exist, then read the entries in the spreadsheet in the first column named âSample Numberâ and create a variable in this Python program named âSampleâ that is one integer value higher than the highest integer number column named âSample Numberâ in the XL, and print this value of 'Sample' to output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ecb5690-396c-4afc-8d5a-9b23f273b1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a sequential number as an identifier for each DataFrame\n",
    "list_df = {f'df_{i + 1}': list_df[i] for i in range(len(list_df))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653288a-3868-419c-a0e5-ac6ba3914ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File path for the ANCHOR XAI metrics results spreadsheet\n",
    "ANCHOR_xai_file_path = 'ANCHOR_XAI_Metrics_Experiments.xlsx'  # Stored locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b5cb374-7e77-49b6-ac0a-e72fafe384ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call Function to update or create the spreadsheet and determine the 'Sample' number\n",
    "# Process each dataframe in 'list_df'\n",
    "sample = return_next_sample_number_to_process(list_df, LIME_xai_file_path, \"LIME\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1351ec4-6420-41be-bc9a-bbe554fdf773",
   "metadata": {},
   "source": [
    "## Select Next Dataframe to Process"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6338def4-4a6d-43ad-b4db-430dfac204c6",
   "metadata": {},
   "source": [
    "---------------------------------\n",
    "\n",
    "\t\n",
    "Extend the Python code so that the code reads in the dataframe from 'list df' that corresponds to the integer value in the \n",
    "variable named âSampleâ. \n",
    "\n",
    "Assign this dataframe the name 'df_Selected_from_List'.\n",
    "\n",
    "\n",
    "----------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2191ad-fab5-49d8-a1b7-483de071ded8",
   "metadata": {},
   "source": [
    "### Initialize Dataframe to Capture Re-start Point as None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c7003e-560f-4327-b597-16d8fa497976",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize df_Selected_from_List as None\n",
    "df_Selected_from_List = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47b362c7-d214-4974-83e6-1604c0e505c9",
   "metadata": {},
   "source": [
    "### Extract test data block to restart XAI metrics process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f305ad-68cc-4d29-8d58-f7269da5ee8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_from_List, key = select_restart_testdata_block(df_Selected_from_List, \n",
    "                                                           list_df, \n",
    "                                                           LIME_xai_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "725d2b62-48a3-4c94-9c37-6d3220d45d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no DataFrame is selected (e.g., if 'Sample' exceeds the number of DataFrames in list_df)\n",
    "if 'df_Selected_from_List' not in locals():\n",
    "    print(\"No DataFrame selected. The 'Sample' number may exceed the number of DataFrames in list_df.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43df2c1-f877-4f68-ba62-ff5273add48e",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f61762-1dda-486a-9fc5-02efa921aa63",
   "metadata": {},
   "source": [
    "## Generate XAI Metrics from Dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575583cc-5b01-4d96-9741-b46e9d783497",
   "metadata": {},
   "source": [
    "### Generate the ANCHOR Values for the Test Data Block"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6461d79-b57d-450e-94db-32189cd0caf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_from_List.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0aaf165-fcb1-4f2d-bfd2-3ff0d1bdd507",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_Selected_from_List.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591636a9-6e3a-4a59-a10d-50e305971dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_from_List = df_Selected_from_List.drop('Fraud', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecddff26-6b82-4cb4-a9df-20f69a3636a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Selected_from_List.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c2b0f-b537-496c-ade6-3c756e996a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_Selected_from_List.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d246b5-e471-407e-8426-e7376ec1c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamically determine start and end indices\n",
    "start_index = df_Selected_from_List.index[0]  # First index of the DataFrame\n",
    "print(f'Start Index is : {start_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97739abe-bdb0-4947-8ecc-abc7b16d48a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "end_index = df_Selected_from_List.index[-1]  # Last index of the DataFrame\n",
    "print(f'End Index is : {end_index}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8709a06-b21b-4a95-a91e-55253ba797a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_range = list(range(start_index, end_index + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c6da5-8121-4d97-aad5-17ebc66f0a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jan 6th - use new loaded model and data\n",
    "default_1_indices = index_range\n",
    "\n",
    "chosen_indices = list(np.random.choice(default_1_indices, 4)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35657476-f385-44b7-a2d3-79bad9a4686a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results_LIME, exec_time_LIME = generate_lime_explanations(df_Selected_from_List, chosen_indices)\n",
    "#results, exec_time = generate_anchors_for_instances(X_test_downsampled, 5)\n",
    "\n",
    "results_ANCHOR, exec_time_ANCHOR = generate_anchors_for_instances(df_Selected_from_List)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234f305b-24a7-4686-b4c3-14cef11194e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpack the results to get features_df, lime_df\n",
    "#features_df_LIME, lime_df = results_LIME\n",
    "#df_feature_instances, new_df_anchor_results = results\n",
    "\n",
    "df_feature_anchor_instances, new_df_anchor_results = results_ANCHOR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870f3bf0-7210-463a-83cd-6ba3bc6c4317",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anchors_numerical = parse_anchor_exps(new_df_anchor_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0540fe51-66df-4f98-96bb-2980a5c7a02a",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c0114b8-2ed0-431f-8a83-05f05a2003c4",
   "metadata": {},
   "source": [
    "### Generate Identity Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183a45e4-d979-4ea3-8076-cc6c7917f0fb",
   "metadata": {},
   "source": [
    "#### Run a Basic Test First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d50bd85-3080-46c4-9846-c3e36c468213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select two random instances from the ANCHOR dataframe\n",
    "df_xai_numerical = df_anchors_numerical\n",
    "\n",
    "random_indices = np.random.choice(df_xai_numerical.index, size=2, replace=False)\n",
    "instance_1 = df_xai_numerical.iloc[random_indices[0]]\n",
    "instance_2 = df_xai_numerical.iloc[random_indices[1]]\n",
    "\n",
    "# Compute the Euclidean distance between the selected instances - uses custom project function\n",
    "distance = get_euclidean_distance(instance_1, instance_2)\n",
    "print(f\"Euclidean distance between instance {random_indices[0]} and instance {random_indices[1]}: {distance:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f59711fa-7b36-4c00-98a8-d7aff50469ef",
   "metadata": {},
   "source": [
    "#### Retrieve Identity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28f36167-26e5-49ab-a94f-1713df0163c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "ANCHOR_Identity_Metric = get_identity_metric(df_feature_anchor_instances, df_anchors_numerical, \"ANCHOR\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ae1ad83-911c-4af0-b296-4dd1f27ed63c",
   "metadata": {},
   "source": [
    "#### Display Identity Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d4d91-7a13-4637-876c-95a0fb3e390e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Identity_Number = \"{:.2f}%\".format(ANCHOR_Identity_Metric)\n",
    "display_text(\"ANCHOR Identity Metric Score: \" + ANCHOR_Identity_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22956d72-c9c3-45ff-85ed-11dedabf3c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Identity\n",
    "XAI_Ident_Metric_1 = ANCHOR_Identity_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c937dd6e-9301-4efc-ad80-bf2b88c25e66",
   "metadata": {},
   "source": [
    "-------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0f32ef-ea85-4594-9f7b-3dcd0baa7615",
   "metadata": {},
   "source": [
    "### Generate Stability Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe2db4-68fa-4a50-9d3e-81f5ec72823a",
   "metadata": {},
   "source": [
    "#### Retrieve Stability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fead5fe6-5798-4a0e-9128-a1501a9707ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Stability_Metric = get_stability_metric_y(df_anchors_numerical, y_test_loaded, 'ANCHOR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1060608-b794-4073-9751-df1b3294c3f9",
   "metadata": {},
   "source": [
    "#### Display Stability Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc4603b-b0d2-43e9-933e-37cce324705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Stability_Number = \"{:.2f}%\".format(ANCHOR_Stability_Metric)\n",
    "display_text(\"ANCHOR Stability Metric Score: \" + ANCHOR_Stability_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae5d620-febe-4aae-b1e6-1ccd403cf3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Stability\n",
    "XAI_Stability_Metric_2 = ANCHOR_Stability_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d820448e-54dd-4818-8bcc-91b047b7ac5e",
   "metadata": {},
   "source": [
    "----------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74a317f-c4af-4639-80f2-38fad643badc",
   "metadata": {},
   "source": [
    "### Generate Seperability Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd40a94b-a2a5-4666-9344-2a4031c17ecf",
   "metadata": {},
   "source": [
    "#### Retrieve Seperability Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9725bbf-927d-469c-bfef-3130bfba9f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Seperability_Metric = get_seperability_metric(df_feature_anchor_instances, df_anchors_numerical, \"ANCHOR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92ffdf04-67ea-469a-a9b7-192f910341b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Display Seperability Score MetricÂ¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d1886d-bea5-476f-923c-09015f49c186",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Seperability_Number = \"{:.2f}%\".format(ANCHOR_Seperability_Metric)\n",
    "display_text(\"ANCHOR Seperability Metric Score: \" + ANCHOR_Seperability_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df4ba1e4-624b-409d-8907-7f9a621287c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Seperability\n",
    "XAI_Seperability_Metric_3 = ANCHOR_Seperability_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31f8e76a-2713-4432-9e6d-9b2483ea5d85",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522d8eda-b31c-4bc6-84de-47575bd12f4c",
   "metadata": {},
   "source": [
    "### Generate Similarity Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f19e03-ba10-4d07-b8da-a6acb5076310",
   "metadata": {},
   "source": [
    "#### Retrieve Similarity Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e988de3c-ff88-4948-aca1-4d717ab9a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Similarity_Metric = get_similarity_metric(df_feature_anchor_instances, df_anchors_numerical, \"ANCHOR\", \n",
    "                                                 use_dbscan=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "458c0bd9-04c1-4d33-9ba7-e052bfbf4f25",
   "metadata": {},
   "source": [
    "#### Display Similarity Score Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f0d8ab-a4e2-4bee-9e60-75800053338b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ANCHOR_Similarity_Number = \"{:6.2f}\".format(ANCHOR_Similarity_Metric)\n",
    "display_text(\"ANCHOR Similarity Metric Value: \" + ANCHOR_Similarity_Number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75d7e3a-5e09-4ca7-a06c-4374e4f060c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in XAI Metric for Similarity\n",
    "XAI_Similarity_Metric_4 = ANCHOR_Similarity_Metric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69674cf-e8ca-4166-abbf-558e9d59804c",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52602c42-bd19-442e-b371-74f677c552e1",
   "metadata": {},
   "source": [
    "### Display Final Set of Metrics (this run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11590dd6-44ae-4e59-bc2c-23d8aa62542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the results\n",
    "print(f\"XAI Ident Metric 1: {XAI_Ident_Metric_1}\")\n",
    "print(f\"XAI Stability Metric 2: {XAI_Stability_Metric_2}\")\n",
    "print(f\"XAI Seperability Metric 1: {XAI_Seperability_Metric_3}\")\n",
    "print(f\"XAI Similarity Metric 1: {XAI_Similarity_Metric_4}\")\n",
    "print(f\"XAI Time Metric 5: {exec_time_ANCHOR} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0ff39cc-b050-48f8-94a6-00a0912e2095",
   "metadata": {},
   "source": [
    "------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d151b620-c616-4ffb-8c76-6b99a9f11609",
   "metadata": {},
   "source": [
    "## Write Out Metrics to XL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93144f1-2731-4dc1-9cd7-19b233444ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_xai_Metrics_to_XL(ANCHOR_xai_file_path, \n",
    "                        sample, \n",
    "                        ANCHOR_Identity_Metric, \n",
    "                        ANCHOR_Stability_Metric, \n",
    "                        ANCHOR_Seperability_Metric, \n",
    "                        ANCHOR_Similarity_Metric, \n",
    "                        exec_time_ANCHOR, \n",
    "                        df_Selected_from_List,\n",
    "                        \"ANCHOR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
